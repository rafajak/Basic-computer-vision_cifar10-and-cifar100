{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "todo: \n",
    "    1. Change optimizer, batch size, test batch size, \n",
    "       to keep it consistent with the keras model\n",
    "    2. Add neptune channels for logloss and acc\n",
    "    3. Run on gpu \n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load pytorch_cif-10.py\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from deepsense import neptune\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neptune: Executing in Offline Mode.\n"
     ]
    }
   ],
   "source": [
    "ctx = neptune.Context()\n",
    "ctx.tags.append('pytorch')\n",
    "ctx.tags.append('cifar-10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "test_batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "# momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 1. Loading and normalizing CIFAR10\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(trainloader.dataset),\n",
    "        len(testloader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# 2. Define a Convolution Neural Network\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64,\n",
    "                               kernel_size=3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 1, padding = 0)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 1, padding = 0)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding = 1)\n",
    "        self.conv6 = nn.Conv2d(256, 256, 1, padding = 0)\n",
    "        self.conv7 = nn.Conv2d(256, 512, 3, padding = 1)\n",
    "        self.conv8 = nn.Conv2d(512, 512, 1, padding = 0)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048,512)\n",
    "        self.fc2 = nn.Linear(512,10)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dropout06 = nn.Dropout(p=0.6)\n",
    "        self.dropout05 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(256)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(512)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "            \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout05(self.pool(F.relu(self.conv2(x))))\n",
    "        \n",
    "        x = F.relu(self.conv3(x))     \n",
    "        x = self.dropout06(self.batchnorm2(self.pool(F.relu(self.conv4(x)))))\n",
    "        \n",
    "        x = F.relu(self.conv5(x))                  \n",
    "        x = self.dropout06(self.batchnorm3(self.pool(F.relu(self.conv6(x)))))\n",
    "        \n",
    "        x = F.relu(self.conv7(x))     \n",
    "        x = self.dropout06(self.pool(F.relu(self.conv8(x))))\n",
    "#         print(x.size())\n",
    "        x = x.view(batch_size, -1)\n",
    "\n",
    "        x = self.dropout05(F.relu(self.fc1(x)))\n",
    "        x = F.softmax(self.fc2(x), dim=-1)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# if cuda: \n",
    "#     model.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.1463  0.0342 -0.0845\n",
      " -0.1463  0.0615 -0.1417\n",
      " -0.1269  0.0931 -0.0585\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.1462 -0.1432  0.0077\n",
      "  0.0371 -0.1210 -0.0680\n",
      "  0.0538 -0.1233 -0.1498\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -0.1379  0.1251  0.1501\n",
      " -0.0240  0.1620  0.0549\n",
      " -0.1144  0.1526  0.0744\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.1166  0.1011 -0.1401\n",
      " -0.0416  0.0745 -0.0259\n",
      " -0.1220 -0.1257  0.1616\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "  0.1890  0.0791 -0.1386\n",
      "  0.0047 -0.0701  0.1614\n",
      "  0.0486 -0.0907  0.1268\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      " -0.1352  0.1787 -0.1372\n",
      " -0.1485 -0.1753 -0.0487\n",
      "  0.0486  0.0877  0.1481\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.1372 -0.1265  0.0264\n",
      " -0.1679 -0.1084  0.0717\n",
      "  0.1327  0.1017 -0.0134\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      "  0.0047  0.1712 -0.1400\n",
      "  0.0341 -0.0356  0.0768\n",
      "  0.1053 -0.0629 -0.0605\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      " -0.0324 -0.0032 -0.0034\n",
      " -0.1826 -0.0942  0.0984\n",
      " -0.1092 -0.1220 -0.0107\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(61,0 ,.,.) = \n",
      "  0.1437  0.0556  0.0710\n",
      "  0.0779  0.0185  0.1398\n",
      "  0.0124 -0.1474 -0.0445\n",
      "\n",
      "(61,1 ,.,.) = \n",
      " -0.1763 -0.0004  0.0624\n",
      "  0.1557 -0.0228 -0.1887\n",
      "  0.0766  0.1011 -0.0698\n",
      "\n",
      "(61,2 ,.,.) = \n",
      "  0.1644  0.0288 -0.0545\n",
      " -0.0868 -0.1477  0.0397\n",
      "  0.0350 -0.1076  0.1006\n",
      "     ⋮ \n",
      "\n",
      "(62,0 ,.,.) = \n",
      "  0.1816 -0.0790 -0.0188\n",
      " -0.1490  0.1229  0.0663\n",
      "  0.1191 -0.0631  0.0957\n",
      "\n",
      "(62,1 ,.,.) = \n",
      "  0.0411 -0.1687 -0.1213\n",
      " -0.0056  0.0197  0.0068\n",
      "  0.1748 -0.0780  0.0837\n",
      "\n",
      "(62,2 ,.,.) = \n",
      " -0.0896 -0.0242  0.1100\n",
      "  0.1182  0.1301  0.0144\n",
      " -0.0031  0.0468  0.0140\n",
      "     ⋮ \n",
      "\n",
      "(63,0 ,.,.) = \n",
      " -0.1213  0.1503 -0.0585\n",
      "  0.0460 -0.0949 -0.1779\n",
      " -0.1022 -0.0062 -0.0593\n",
      "\n",
      "(63,1 ,.,.) = \n",
      " -0.1304  0.1172  0.0871\n",
      "  0.0318 -0.1249  0.0780\n",
      "  0.1147 -0.1871  0.1161\n",
      "\n",
      "(63,2 ,.,.) = \n",
      "  0.1205  0.0369  0.0258\n",
      " -0.1568 -0.1597  0.1150\n",
      "  0.1374  0.1491 -0.0771\n",
      "[torch.FloatTensor of size 64x3x3x3]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0569\n",
      "-0.1088\n",
      " 0.0000\n",
      "-0.1510\n",
      " 0.0532\n",
      "-0.1476\n",
      "-0.0887\n",
      "-0.1189\n",
      " 0.0904\n",
      " 0.0006\n",
      " 0.0481\n",
      "-0.1611\n",
      " 0.1246\n",
      "-0.1463\n",
      " 0.1679\n",
      " 0.1565\n",
      " 0.0625\n",
      " 0.1285\n",
      " 0.0782\n",
      "-0.0009\n",
      "-0.0555\n",
      " 0.0774\n",
      " 0.0391\n",
      "-0.0317\n",
      "-0.0909\n",
      "-0.0408\n",
      "-0.1011\n",
      "-0.0469\n",
      "-0.0498\n",
      "-0.1712\n",
      "-0.0371\n",
      " 0.1729\n",
      " 0.1029\n",
      " 0.0273\n",
      "-0.0463\n",
      "-0.1627\n",
      "-0.0478\n",
      " 0.0538\n",
      " 0.0377\n",
      " 0.1746\n",
      " 0.1142\n",
      "-0.1054\n",
      "-0.1599\n",
      " 0.0187\n",
      " 0.1010\n",
      " 0.0977\n",
      "-0.0483\n",
      " 0.1627\n",
      "-0.0226\n",
      " 0.0661\n",
      " 0.1017\n",
      " 0.0482\n",
      " 0.0302\n",
      " 0.0785\n",
      "-0.1729\n",
      " 0.0647\n",
      " 0.1010\n",
      "-0.1841\n",
      "-0.0473\n",
      "-0.0942\n",
      "-0.1055\n",
      "-0.1827\n",
      " 0.1247\n",
      " 0.1300\n",
      "[torch.FloatTensor of size 64]\n",
      "\n",
      "Parameter containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -3.6111e-02\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -7.3969e-02\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  8.2953e-02\n",
      "   ...\n",
      "\n",
      "(0 ,61,.,.) = \n",
      " -1.1959e-01\n",
      "\n",
      "(0 ,62,.,.) = \n",
      "  7.5207e-02\n",
      "\n",
      "(0 ,63,.,.) = \n",
      "  1.1775e-01\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      "  2.0071e-03\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      "  8.5655e-02\n",
      "\n",
      "(1 ,2 ,.,.) = \n",
      "  5.7777e-02\n",
      "   ...\n",
      "\n",
      "(1 ,61,.,.) = \n",
      " -1.1952e-01\n",
      "\n",
      "(1 ,62,.,.) = \n",
      " -9.1869e-02\n",
      "\n",
      "(1 ,63,.,.) = \n",
      "  6.8002e-02\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      "  4.1904e-02\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -6.2051e-02\n",
      "\n",
      "(2 ,2 ,.,.) = \n",
      "  8.0119e-02\n",
      "   ...\n",
      "\n",
      "(2 ,61,.,.) = \n",
      "  1.1664e-01\n",
      "\n",
      "(2 ,62,.,.) = \n",
      "  9.5182e-02\n",
      "\n",
      "(2 ,63,.,.) = \n",
      " -7.5513e-02\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(61,0 ,.,.) = \n",
      " -8.0587e-02\n",
      "\n",
      "(61,1 ,.,.) = \n",
      " -2.3449e-02\n",
      "\n",
      "(61,2 ,.,.) = \n",
      "  1.0362e-01\n",
      "   ...\n",
      "\n",
      "(61,61,.,.) = \n",
      "  6.4424e-02\n",
      "\n",
      "(61,62,.,.) = \n",
      " -1.9143e-02\n",
      "\n",
      "(61,63,.,.) = \n",
      "  1.2177e-01\n",
      "     ⋮ \n",
      "\n",
      "(62,0 ,.,.) = \n",
      "  6.8795e-02\n",
      "\n",
      "(62,1 ,.,.) = \n",
      "  2.1427e-02\n",
      "\n",
      "(62,2 ,.,.) = \n",
      " -6.0783e-03\n",
      "   ...\n",
      "\n",
      "(62,61,.,.) = \n",
      "  3.2413e-03\n",
      "\n",
      "(62,62,.,.) = \n",
      "  5.6338e-02\n",
      "\n",
      "(62,63,.,.) = \n",
      " -4.2998e-02\n",
      "     ⋮ \n",
      "\n",
      "(63,0 ,.,.) = \n",
      " -7.4520e-02\n",
      "\n",
      "(63,1 ,.,.) = \n",
      " -5.5535e-02\n",
      "\n",
      "(63,2 ,.,.) = \n",
      " -7.6604e-02\n",
      "   ...\n",
      "\n",
      "(63,61,.,.) = \n",
      "  1.1300e-01\n",
      "\n",
      "(63,62,.,.) = \n",
      " -5.8806e-02\n",
      "\n",
      "(63,63,.,.) = \n",
      "  1.0010e-01\n",
      "[torch.FloatTensor of size 64x64x1x1]\n",
      "\n",
      "Parameter containing:\n",
      " 0.0777\n",
      " 0.1128\n",
      " 0.1230\n",
      " 0.0657\n",
      " 0.0735\n",
      "-0.0245\n",
      "-0.0643\n",
      " 0.0175\n",
      " 0.0453\n",
      " 0.0568\n",
      "-0.0836\n",
      " 0.0632\n",
      " 0.0058\n",
      "-0.0172\n",
      " 0.0433\n",
      " 0.0262\n",
      "-0.0800\n",
      "-0.0490\n",
      " 0.1219\n",
      "-0.0503\n",
      "-0.0389\n",
      "-0.1028\n",
      "-0.1225\n",
      " 0.0873\n",
      "-0.0290\n",
      "-0.0260\n",
      "-0.1180\n",
      " 0.1163\n",
      "-0.0581\n",
      " 0.0399\n",
      "-0.0444\n",
      " 0.0861\n",
      "-0.0252\n",
      " 0.0908\n",
      " 0.0981\n",
      "-0.0952\n",
      " 0.0992\n",
      "-0.0360\n",
      "-0.0265\n",
      " 0.0590\n",
      " 0.0057\n",
      "-0.0023\n",
      "-0.0168\n",
      "-0.1089\n",
      " 0.0988\n",
      "-0.1247\n",
      "-0.0797\n",
      " 0.0703\n",
      "-0.0278\n",
      "-0.0981\n",
      "-0.0852\n",
      "-0.0564\n",
      "-0.0355\n",
      "-0.1134\n",
      "-0.0725\n",
      "-0.0574\n",
      "-0.0857\n",
      "-0.0306\n",
      "-0.0167\n",
      "-0.0861\n",
      "-0.0500\n",
      " 0.0100\n",
      "-0.0077\n",
      " 0.0032\n",
      "[torch.FloatTensor of size 64]\n",
      "\n",
      "Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      " -1.8815e-02  2.3293e-02 -2.9386e-02\n",
      " -3.3636e-02 -1.2768e-02 -3.1316e-02\n",
      " -3.4788e-03  5.3266e-03 -3.8943e-02\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  1.2755e-02  2.1041e-02  2.3561e-02\n",
      "  8.6691e-03 -2.6603e-02  2.9647e-02\n",
      "  2.2065e-02  7.2739e-03 -2.9670e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -3.9750e-02  3.9672e-02  2.8897e-02\n",
      " -8.3584e-03 -5.9104e-03  4.0617e-02\n",
      " -9.6881e-03  3.5113e-02 -1.8850e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,61 ,.,.) = \n",
      " -3.2113e-02  9.6030e-03 -3.3823e-02\n",
      " -3.4028e-02  3.4772e-02  2.7401e-02\n",
      "  1.2965e-02 -2.9701e-02 -1.3090e-02\n",
      "\n",
      "( 0 ,62 ,.,.) = \n",
      " -2.1498e-02  3.4302e-02 -3.6839e-02\n",
      " -1.9216e-02 -1.9478e-02  3.6356e-02\n",
      " -2.0532e-02  2.7817e-02  2.5998e-02\n",
      "\n",
      "( 0 ,63 ,.,.) = \n",
      "  2.7294e-02 -3.2990e-02  1.6156e-02\n",
      "  2.0440e-02 -2.1564e-02  2.6526e-02\n",
      "  2.4034e-02 -3.4676e-03 -3.4456e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      " -2.2839e-02  7.1789e-03  1.4353e-02\n",
      "  5.8946e-03 -2.2554e-02  3.3732e-02\n",
      " -3.7700e-02  3.4690e-02 -1.6535e-02\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      " -4.1303e-02 -9.2125e-03  3.8888e-02\n",
      " -1.9906e-02 -3.7021e-02 -7.1341e-03\n",
      " -2.3316e-02  1.2447e-02  4.1619e-02\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      " -3.9159e-03  2.5213e-02 -3.8843e-03\n",
      "  2.9914e-02 -2.5099e-03  2.9581e-02\n",
      "  3.1283e-02 -8.4981e-03  2.4908e-02\n",
      "    ... \n",
      "\n",
      "( 1 ,61 ,.,.) = \n",
      "  3.4047e-02 -8.5703e-03 -2.8685e-02\n",
      " -1.2607e-02 -8.8355e-03  7.2780e-03\n",
      " -1.1195e-02 -2.3253e-02  1.2397e-02\n",
      "\n",
      "( 1 ,62 ,.,.) = \n",
      "  3.4260e-02 -2.2950e-02 -3.1634e-02\n",
      " -2.0886e-02  3.0264e-02  2.7330e-02\n",
      " -1.3703e-02 -3.5211e-03 -3.2173e-02\n",
      "\n",
      "( 1 ,63 ,.,.) = \n",
      "  3.4371e-02 -2.1726e-02  4.1955e-03\n",
      " -8.9659e-03 -2.8636e-02  7.9282e-03\n",
      " -3.6577e-02 -1.4994e-03  1.4913e-02\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      " -3.8764e-02  1.1845e-02  1.7076e-02\n",
      " -7.9567e-03 -1.5509e-02 -3.1330e-02\n",
      " -8.0292e-03 -3.9298e-02 -2.5574e-02\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  1.2188e-02 -2.5627e-02 -3.4574e-02\n",
      "  9.8342e-03  1.1839e-02  1.1674e-02\n",
      "  4.8599e-03  2.0047e-03 -4.0953e-02\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      " -3.9675e-02 -2.7920e-02 -3.2181e-02\n",
      "  4.0481e-02 -2.4708e-02  1.4826e-02\n",
      "  9.2392e-04  7.8365e-03  3.2139e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,61 ,.,.) = \n",
      "  1.9528e-03  3.3014e-02  1.7979e-02\n",
      "  1.8175e-02 -8.3837e-03 -3.8880e-03\n",
      " -1.1416e-02  1.7665e-02 -1.5977e-03\n",
      "\n",
      "( 2 ,62 ,.,.) = \n",
      "  3.9849e-02 -6.0243e-03 -2.3807e-02\n",
      "  1.8159e-03 -1.4576e-03 -2.7031e-02\n",
      "  3.5950e-02  7.9352e-03 -3.6312e-02\n",
      "\n",
      "( 2 ,63 ,.,.) = \n",
      " -1.6926e-02 -3.7206e-02 -2.7399e-02\n",
      "  3.5788e-02 -9.2421e-03  3.0743e-02\n",
      "  4.7893e-03  2.7050e-02  3.0564e-02\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(125, 0 ,.,.) = \n",
      "  1.5108e-02 -1.3530e-02 -3.4809e-02\n",
      " -1.1054e-02 -1.4293e-02 -8.8889e-03\n",
      "  1.2442e-02 -1.1757e-04  3.0458e-02\n",
      "\n",
      "(125, 1 ,.,.) = \n",
      " -7.8029e-03  8.1114e-03 -3.6297e-02\n",
      "  5.1315e-03 -3.4067e-03 -9.8910e-03\n",
      "  4.1475e-02  2.7961e-02 -2.3261e-02\n",
      "\n",
      "(125, 2 ,.,.) = \n",
      "  3.9266e-02 -3.9630e-02 -2.3506e-02\n",
      "  9.1931e-03  4.0303e-02  1.4363e-02\n",
      " -3.1813e-02  4.4463e-03 -1.0900e-02\n",
      "    ... \n",
      "\n",
      "(125,61 ,.,.) = \n",
      " -1.8265e-02 -2.3805e-02  1.8472e-02\n",
      "  5.5533e-03 -1.6838e-02  1.2197e-03\n",
      " -2.1270e-02  3.1704e-02  3.7779e-02\n",
      "\n",
      "(125,62 ,.,.) = \n",
      "  3.0178e-02  3.7020e-02  2.9346e-02\n",
      "  2.9179e-02 -1.8328e-02  2.6969e-02\n",
      " -6.4102e-03 -2.4503e-02  4.0545e-02\n",
      "\n",
      "(125,63 ,.,.) = \n",
      "  3.4036e-02 -3.2100e-03  1.7450e-02\n",
      " -3.1054e-02  2.8900e-03  5.1925e-03\n",
      " -7.3401e-03 -1.4794e-02  6.3663e-04\n",
      "      ⋮  \n",
      "\n",
      "(126, 0 ,.,.) = \n",
      " -6.3249e-03 -3.4337e-02  2.1859e-02\n",
      " -1.2429e-02 -3.2405e-02 -3.4222e-02\n",
      "  2.3374e-03  9.8413e-03  2.6421e-03\n",
      "\n",
      "(126, 1 ,.,.) = \n",
      " -2.7020e-02  2.7994e-02  1.0438e-02\n",
      " -1.1290e-02 -2.0106e-02 -1.7847e-02\n",
      "  2.9734e-03  1.6172e-03 -1.1282e-02\n",
      "\n",
      "(126, 2 ,.,.) = \n",
      "  3.0383e-02 -3.2906e-02  1.7342e-02\n",
      " -2.2083e-02 -3.2487e-02 -1.1528e-02\n",
      "  2.3885e-02 -4.7643e-04  3.0863e-02\n",
      "    ... \n",
      "\n",
      "(126,61 ,.,.) = \n",
      " -1.8631e-02 -9.7915e-03  3.5583e-02\n",
      " -3.4795e-02 -2.5357e-02 -1.0269e-02\n",
      " -2.9950e-02  1.9704e-02  2.2659e-03\n",
      "\n",
      "(126,62 ,.,.) = \n",
      " -2.2390e-02 -6.2947e-04 -1.6338e-02\n",
      "  3.6976e-02 -3.0895e-02 -3.8656e-02\n",
      "  1.8149e-02 -1.7169e-02 -1.5664e-02\n",
      "\n",
      "(126,63 ,.,.) = \n",
      "  3.7852e-02 -4.7472e-03  8.5507e-03\n",
      " -3.2101e-02 -4.1580e-02 -1.8115e-02\n",
      " -1.7060e-02  3.5163e-02  3.3122e-02\n",
      "      ⋮  \n",
      "\n",
      "(127, 0 ,.,.) = \n",
      "  2.5834e-03  1.4197e-02  3.4584e-02\n",
      " -1.5799e-02 -1.7802e-02 -3.8250e-02\n",
      "  3.2756e-02 -9.1854e-03  1.8721e-02\n",
      "\n",
      "(127, 1 ,.,.) = \n",
      " -1.7717e-02 -3.8483e-02 -3.0623e-03\n",
      "  2.8824e-02  2.2951e-02  2.6174e-02\n",
      "  3.6732e-02  8.4073e-03 -6.9832e-03\n",
      "\n",
      "(127, 2 ,.,.) = \n",
      "  7.5523e-03  3.9482e-02 -7.4932e-03\n",
      "  3.9031e-02 -3.5956e-02 -2.4353e-02\n",
      " -4.0074e-02  2.1718e-02 -2.8995e-02\n",
      "    ... \n",
      "\n",
      "(127,61 ,.,.) = \n",
      "  1.5963e-02 -1.2975e-02  1.6327e-03\n",
      "  3.5530e-02 -3.2632e-02  1.0270e-02\n",
      "  9.3208e-03 -8.3133e-03  3.2806e-02\n",
      "\n",
      "(127,62 ,.,.) = \n",
      " -2.8071e-02  1.7205e-02 -2.5207e-03\n",
      "  2.6833e-02 -6.0738e-03  2.6820e-02\n",
      "  1.9651e-02  1.1882e-03  1.7023e-02\n",
      "\n",
      "(127,63 ,.,.) = \n",
      " -2.8087e-02 -1.3782e-02  1.7269e-02\n",
      " -1.4864e-02  4.0450e-02 -3.9307e-03\n",
      "  5.1794e-03  2.4328e-02  2.1965e-02\n",
      "[torch.FloatTensor of size 128x64x3x3]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "  0.4049\n",
      "  0.4229\n",
      " -3.9003\n",
      " -2.9621\n",
      " -1.6387\n",
      "  3.5123\n",
      "  2.4264\n",
      "  0.0181\n",
      " -0.7467\n",
      "  0.2125\n",
      " -1.5379\n",
      " -1.0253\n",
      "  0.4128\n",
      "  2.8063\n",
      " -1.7462\n",
      " -2.5926\n",
      " -1.6481\n",
      "  2.3451\n",
      " -2.6583\n",
      "  3.2427\n",
      "  1.4471\n",
      "  2.1642\n",
      " -3.0419\n",
      " -1.4537\n",
      " -3.2774\n",
      " -4.1099\n",
      " -1.2400\n",
      "  1.7056\n",
      "  1.9284\n",
      "  2.7892\n",
      " -2.8356\n",
      " -3.3024\n",
      " -3.6525\n",
      "  1.4767\n",
      " -2.6396\n",
      "  3.1940\n",
      " -0.2546\n",
      "  3.2023\n",
      " -0.2937\n",
      "  2.2729\n",
      " -4.0804\n",
      "  3.1655\n",
      " -1.5194\n",
      "  0.8939\n",
      "  3.3186\n",
      "  2.0408\n",
      "  2.7604\n",
      "  2.8564\n",
      " -1.6159\n",
      " -0.5797\n",
      "  1.7737\n",
      "  2.0656\n",
      "  3.5999\n",
      "  1.7304\n",
      "  3.1953\n",
      "  0.8114\n",
      " -3.3127\n",
      " -1.0687\n",
      " -1.5275\n",
      " -2.2360\n",
      " -3.0326\n",
      " -2.9245\n",
      "  0.5118\n",
      " -1.1550\n",
      " -3.5668\n",
      " -1.5715\n",
      "  0.5792\n",
      " -0.0479\n",
      "  2.6375\n",
      " -3.7275\n",
      " -4.1237\n",
      "  2.9623\n",
      "  1.5241\n",
      " -2.2452\n",
      " -1.8895\n",
      " -2.3820\n",
      "  1.1223\n",
      "  2.4262\n",
      "  3.9869\n",
      "  0.5015\n",
      "  3.1667\n",
      "  1.8863\n",
      " -1.4783\n",
      "  2.0263\n",
      "  1.2284\n",
      " -1.4803\n",
      "  2.8046\n",
      "  1.3907\n",
      " -0.9386\n",
      "  3.9189\n",
      "  4.0602\n",
      " -3.8413\n",
      "  1.8057\n",
      " -0.8612\n",
      " -2.0642\n",
      " -0.9730\n",
      " -0.7837\n",
      " -4.0530\n",
      " -3.0159\n",
      "  2.5920\n",
      "  3.4312\n",
      " -2.8957\n",
      "  0.2609\n",
      " -3.7774\n",
      "  0.8358\n",
      " -3.0750\n",
      " -0.1694\n",
      "  2.7730\n",
      " -0.4062\n",
      "  2.3502\n",
      " -0.1650\n",
      "  2.3900\n",
      " -2.3742\n",
      " -1.4394\n",
      " -1.9298\n",
      " -0.6101\n",
      "  0.5236\n",
      " -0.8847\n",
      " -0.6363\n",
      " -2.8575\n",
      "  1.0326\n",
      " -0.9315\n",
      "  1.1996\n",
      " -1.7325\n",
      " -0.4440\n",
      " -3.5229\n",
      "  3.0805\n",
      "  1.5294\n",
      "[torch.FloatTensor of size 128]\n",
      "\n",
      "Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  7.6325e-02\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -4.9154e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  4.1873e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,125,.,.) = \n",
      " -6.8311e-02\n",
      "\n",
      "( 0 ,126,.,.) = \n",
      "  2.7412e-02\n",
      "\n",
      "( 0 ,127,.,.) = \n",
      "  4.8015e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  7.7069e-02\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  4.6442e-02\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      " -6.2579e-02\n",
      "    ... \n",
      "\n",
      "( 1 ,125,.,.) = \n",
      " -8.1159e-02\n",
      "\n",
      "( 1 ,126,.,.) = \n",
      "  7.1924e-03\n",
      "\n",
      "( 1 ,127,.,.) = \n",
      "  4.7568e-02\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  3.7440e-02\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      " -6.9923e-02\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      " -4.9033e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,125,.,.) = \n",
      "  3.3774e-02\n",
      "\n",
      "( 2 ,126,.,.) = \n",
      "  6.5403e-02\n",
      "\n",
      "( 2 ,127,.,.) = \n",
      "  6.1656e-02\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(125, 0 ,.,.) = \n",
      " -1.1182e-03\n",
      "\n",
      "(125, 1 ,.,.) = \n",
      " -4.2283e-03\n",
      "\n",
      "(125, 2 ,.,.) = \n",
      "  1.4518e-02\n",
      "    ... \n",
      "\n",
      "(125,125,.,.) = \n",
      "  6.5267e-02\n",
      "\n",
      "(125,126,.,.) = \n",
      " -6.0217e-02\n",
      "\n",
      "(125,127,.,.) = \n",
      "  5.6900e-02\n",
      "      ⋮  \n",
      "\n",
      "(126, 0 ,.,.) = \n",
      "  3.4553e-02\n",
      "\n",
      "(126, 1 ,.,.) = \n",
      " -8.4361e-02\n",
      "\n",
      "(126, 2 ,.,.) = \n",
      " -4.2711e-02\n",
      "    ... \n",
      "\n",
      "(126,125,.,.) = \n",
      "  6.3936e-03\n",
      "\n",
      "(126,126,.,.) = \n",
      " -4.1855e-02\n",
      "\n",
      "(126,127,.,.) = \n",
      "  1.8581e-02\n",
      "      ⋮  \n",
      "\n",
      "(127, 0 ,.,.) = \n",
      "  3.9600e-02\n",
      "\n",
      "(127, 1 ,.,.) = \n",
      " -5.8216e-02\n",
      "\n",
      "(127, 2 ,.,.) = \n",
      "  4.6588e-02\n",
      "    ... \n",
      "\n",
      "(127,125,.,.) = \n",
      " -7.6208e-02\n",
      "\n",
      "(127,126,.,.) = \n",
      " -1.3296e-03\n",
      "\n",
      "(127,127,.,.) = \n",
      " -4.7847e-02\n",
      "[torch.FloatTensor of size 128x128x1x1]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " -8.5887\n",
      " -0.7750\n",
      "  6.6672\n",
      "  2.7162\n",
      " -0.1685\n",
      "  7.9930\n",
      " -4.2256\n",
      " -2.7594\n",
      "  7.0965\n",
      "  7.0481\n",
      " -7.1226\n",
      "  7.3718\n",
      "  0.5314\n",
      " -0.4474\n",
      "  5.2074\n",
      " -5.7992\n",
      "  1.4541\n",
      "  7.0422\n",
      "  3.5035\n",
      " -8.5611\n",
      "  6.1908\n",
      "  3.7186\n",
      " -4.1689\n",
      " -0.9024\n",
      " -5.6050\n",
      " -5.5641\n",
      "  4.9403\n",
      "  0.5930\n",
      " -4.8468\n",
      " -5.6199\n",
      " -1.9786\n",
      " -4.0656\n",
      "  1.2912\n",
      "  1.5868\n",
      "  0.6735\n",
      " -6.8332\n",
      "  7.8673\n",
      " -5.7517\n",
      "  1.1676\n",
      " -0.4294\n",
      "  6.5810\n",
      " -3.9851\n",
      "  3.4452\n",
      "  6.6471\n",
      "  4.8147\n",
      "  6.2167\n",
      " -7.9140\n",
      " -1.5057\n",
      " -2.8687\n",
      "  2.5697\n",
      " -7.6146\n",
      " -7.7944\n",
      "  5.3208\n",
      " -7.4711\n",
      "  0.0898\n",
      " -6.9291\n",
      "  6.7958\n",
      "  4.7262\n",
      " -6.3522\n",
      " -5.9278\n",
      "  1.5420\n",
      " -4.4504\n",
      "  0.0136\n",
      " -7.1176\n",
      "  0.3903\n",
      "  8.1485\n",
      "  4.9599\n",
      " -6.4273\n",
      " -2.4046\n",
      " -0.3912\n",
      " -7.7453\n",
      " -2.0343\n",
      " -5.8303\n",
      "  3.4206\n",
      " -4.3964\n",
      "  1.7017\n",
      " -6.8759\n",
      "  1.1436\n",
      " -2.9340\n",
      "  6.7468\n",
      " -5.2622\n",
      "  7.4668\n",
      " -8.1910\n",
      "  2.0498\n",
      "  7.2151\n",
      " -1.9184\n",
      "  6.0120\n",
      " -7.1125\n",
      "  6.9319\n",
      "  1.1557\n",
      "  1.8121\n",
      "  0.3164\n",
      "  7.7704\n",
      "  2.0417\n",
      " -4.3833\n",
      "  2.9744\n",
      " -3.4588\n",
      " -3.3106\n",
      "  8.3750\n",
      "  2.1971\n",
      "  2.6600\n",
      " -8.3812\n",
      "  8.6918\n",
      " -1.7070\n",
      "  3.5884\n",
      " -0.9665\n",
      "  3.1279\n",
      " -6.0470\n",
      "  3.7213\n",
      " -6.1770\n",
      "  8.3456\n",
      " -6.4440\n",
      " -6.4845\n",
      " -3.2884\n",
      "  5.3700\n",
      "  8.4472\n",
      "  8.5996\n",
      "  2.6436\n",
      "  6.8579\n",
      "  7.3395\n",
      " -7.8089\n",
      " -3.1566\n",
      " -2.9729\n",
      " -3.5649\n",
      "  4.3490\n",
      " -3.5645\n",
      "  0.6922\n",
      " -7.0287\n",
      "[torch.FloatTensor of size 128]\n",
      "\n",
      "Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  2.6287e-02  1.0635e-02  1.4428e-02\n",
      "  1.7615e-02 -1.9184e-02 -8.8994e-03\n",
      " -1.7495e-02 -1.4267e-03  9.0699e-03\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  2.2813e-02 -4.3392e-03  2.8345e-02\n",
      " -5.8752e-03  1.8489e-02 -1.8125e-02\n",
      " -2.9395e-02  9.6431e-03 -1.5800e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  9.7263e-03 -8.8583e-03  2.8702e-02\n",
      "  1.9308e-02  1.5451e-02 -2.1484e-02\n",
      " -1.6208e-02 -1.6546e-02 -2.7904e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,125,.,.) = \n",
      " -1.4964e-03 -6.8325e-04 -3.9731e-03\n",
      " -1.0852e-02  1.7668e-02 -3.1696e-03\n",
      "  6.8461e-03 -1.4753e-02  8.4090e-03\n",
      "\n",
      "( 0 ,126,.,.) = \n",
      "  3.5922e-03 -2.6031e-02  2.6373e-03\n",
      "  9.2223e-03 -1.4189e-02  3.4142e-03\n",
      " -1.4722e-02  2.1998e-02  2.0705e-02\n",
      "\n",
      "( 0 ,127,.,.) = \n",
      " -1.7508e-02 -1.3677e-02  7.7330e-03\n",
      " -2.3103e-02 -2.4729e-02 -1.4557e-02\n",
      "  9.4540e-03  1.5296e-02  2.7773e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      " -2.6973e-02  2.3775e-02 -2.2639e-02\n",
      "  7.3681e-03  9.4831e-03  1.9708e-02\n",
      "  2.4011e-02  1.9490e-02 -5.4361e-03\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  1.5286e-02  2.0476e-02 -1.1728e-02\n",
      "  1.2994e-02  9.9158e-03  9.1484e-04\n",
      "  2.3083e-02 -1.2203e-02  9.8077e-03\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      " -9.9688e-03  1.7208e-02  5.7296e-04\n",
      " -2.1219e-02 -2.1071e-02 -2.8249e-02\n",
      "  1.4198e-02 -1.4658e-02  3.5161e-03\n",
      "    ... \n",
      "\n",
      "( 1 ,125,.,.) = \n",
      " -5.6617e-03 -2.2113e-02 -9.7276e-03\n",
      " -6.5509e-03 -1.8986e-02  2.8778e-02\n",
      "  1.9694e-02 -1.3559e-02  1.4479e-02\n",
      "\n",
      "( 1 ,126,.,.) = \n",
      " -5.4819e-03 -2.6998e-02 -2.0969e-02\n",
      "  2.1607e-02  1.5640e-02  1.1921e-02\n",
      " -2.9235e-02 -2.7011e-02  2.4985e-02\n",
      "\n",
      "( 1 ,127,.,.) = \n",
      " -1.9593e-03  1.1700e-02 -2.4979e-02\n",
      "  2.0294e-02 -1.4365e-02 -6.8677e-03\n",
      "  2.9152e-02  2.7868e-02 -8.2387e-03\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      "  1.2096e-02 -2.7867e-02 -8.1739e-03\n",
      " -9.2046e-03  2.9137e-03 -2.7740e-02\n",
      " -2.0414e-02 -1.7792e-02  2.5607e-02\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      " -2.4612e-02  8.2770e-03  1.1471e-02\n",
      "  1.7381e-03  5.1425e-03 -7.0178e-03\n",
      "  9.5644e-04 -1.8128e-03 -1.7324e-02\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      " -1.5765e-02  1.0044e-02 -2.5125e-02\n",
      "  1.2791e-02  1.0449e-02  2.9342e-02\n",
      " -2.4334e-02  4.9367e-03  1.8977e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,125,.,.) = \n",
      " -1.4072e-02  1.9023e-02  2.5991e-02\n",
      "  1.2871e-02  2.7365e-03 -1.6939e-02\n",
      " -4.8628e-04 -1.3773e-02  2.6942e-02\n",
      "\n",
      "( 2 ,126,.,.) = \n",
      "  6.6281e-03  9.6662e-03  5.8312e-03\n",
      "  2.2491e-03 -2.1221e-02  2.2535e-02\n",
      " -2.1429e-02  1.8745e-02 -6.5058e-03\n",
      "\n",
      "( 2 ,127,.,.) = \n",
      " -1.4600e-02 -1.7286e-02 -1.2031e-02\n",
      " -3.7460e-03 -2.3117e-02 -4.7596e-03\n",
      "  3.9101e-03  1.5158e-02  1.9588e-02\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(253, 0 ,.,.) = \n",
      " -3.1804e-03  9.7462e-03 -2.4801e-02\n",
      " -2.1229e-02  2.1564e-02  1.0444e-02\n",
      " -2.4883e-02 -1.2223e-02 -1.3703e-02\n",
      "\n",
      "(253, 1 ,.,.) = \n",
      "  2.3019e-03  1.3514e-02  1.2101e-02\n",
      "  1.1279e-02 -1.1634e-02 -2.1502e-02\n",
      "  2.4358e-02 -2.4331e-02 -2.0832e-02\n",
      "\n",
      "(253, 2 ,.,.) = \n",
      "  1.2225e-02 -1.7769e-02  1.6334e-02\n",
      "  7.4759e-03 -2.5940e-02 -1.3019e-02\n",
      "  7.4848e-03  2.6242e-02 -2.4333e-02\n",
      "    ... \n",
      "\n",
      "(253,125,.,.) = \n",
      "  2.3454e-02  1.1282e-02  9.0341e-03\n",
      " -5.9843e-03 -1.8834e-02  2.4077e-02\n",
      " -1.6047e-02 -1.8756e-02 -2.3456e-02\n",
      "\n",
      "(253,126,.,.) = \n",
      "  2.3301e-02 -7.9577e-03  2.0317e-02\n",
      "  2.0177e-02  8.1139e-03  2.8177e-02\n",
      "  2.3290e-02 -5.6276e-03 -4.2345e-03\n",
      "\n",
      "(253,127,.,.) = \n",
      "  1.5932e-03 -2.9086e-02  3.8411e-03\n",
      "  1.9246e-02 -1.1031e-02 -8.3781e-04\n",
      "  6.4086e-04 -4.1584e-03 -2.4910e-02\n",
      "      ⋮  \n",
      "\n",
      "(254, 0 ,.,.) = \n",
      "  7.3059e-03 -1.8739e-02  2.3399e-02\n",
      " -2.1303e-02  1.6153e-02  1.1737e-02\n",
      "  2.3534e-02 -1.9049e-02 -5.4659e-04\n",
      "\n",
      "(254, 1 ,.,.) = \n",
      "  2.0383e-02 -2.3466e-03  4.1294e-03\n",
      " -6.3547e-03  1.7739e-02 -4.7998e-03\n",
      " -1.3842e-02 -9.1576e-03  2.7254e-02\n",
      "\n",
      "(254, 2 ,.,.) = \n",
      " -1.8228e-02 -2.1618e-02 -1.1607e-02\n",
      "  2.1282e-02  1.7961e-02  1.3951e-02\n",
      " -2.7902e-02 -2.9230e-02 -2.8436e-02\n",
      "    ... \n",
      "\n",
      "(254,125,.,.) = \n",
      "  2.3333e-02  2.7523e-02 -7.4908e-03\n",
      "  6.6561e-04  8.6742e-03 -6.6688e-03\n",
      "  1.3071e-02  3.2451e-03 -2.0916e-02\n",
      "\n",
      "(254,126,.,.) = \n",
      "  5.4660e-03  1.9421e-02  3.9082e-03\n",
      "  2.0412e-02 -5.0239e-03 -3.4725e-03\n",
      " -1.4531e-02 -1.1890e-03 -5.0766e-03\n",
      "\n",
      "(254,127,.,.) = \n",
      "  2.9959e-04 -2.3366e-02 -4.8217e-03\n",
      " -1.0085e-02 -8.7855e-03 -1.4663e-03\n",
      " -2.6589e-02  2.5857e-02 -5.2947e-03\n",
      "      ⋮  \n",
      "\n",
      "(255, 0 ,.,.) = \n",
      " -2.7849e-02  4.8808e-03  1.2114e-03\n",
      "  2.8175e-02 -4.4045e-03 -2.9022e-02\n",
      " -6.7047e-03 -2.1864e-02  2.3420e-02\n",
      "\n",
      "(255, 1 ,.,.) = \n",
      " -1.7106e-03 -2.8760e-02  8.3553e-03\n",
      " -2.4799e-02  2.2295e-02 -1.3763e-02\n",
      "  1.3515e-02  1.4090e-02 -5.9509e-03\n",
      "\n",
      "(255, 2 ,.,.) = \n",
      " -2.7076e-02  6.3053e-03 -2.5226e-02\n",
      "  1.9678e-02 -1.0612e-02 -8.1815e-03\n",
      " -1.0156e-02 -2.6124e-02 -1.1160e-02\n",
      "    ... \n",
      "\n",
      "(255,125,.,.) = \n",
      "  3.5795e-03  2.1899e-02  4.7589e-04\n",
      " -1.7774e-02  3.5413e-03  4.4499e-03\n",
      "  5.9870e-03 -1.1430e-02  2.2757e-03\n",
      "\n",
      "(255,126,.,.) = \n",
      " -2.0059e-02  4.4406e-03  2.5093e-02\n",
      " -1.9401e-03  2.2520e-02  3.6222e-03\n",
      "  9.8255e-03 -1.0557e-02 -1.7456e-02\n",
      "\n",
      "(255,127,.,.) = \n",
      "  2.1567e-02  2.2590e-02  1.5295e-02\n",
      " -8.0816e-04 -2.0396e-02 -2.1345e-02\n",
      " -2.1490e-02  2.8166e-02 -2.4488e-03\n",
      "[torch.FloatTensor of size 256x128x3x3]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " -2.1245\n",
      " -0.8365\n",
      "  2.4023\n",
      "  0.7564\n",
      "  2.0850\n",
      "  1.9270\n",
      "  0.0192\n",
      "  2.4691\n",
      " -0.4486\n",
      "  0.6582\n",
      "  2.1305\n",
      "  1.7603\n",
      " -1.8134\n",
      " -0.0604\n",
      " -0.1311\n",
      "  2.6799\n",
      " -0.3243\n",
      " -1.0390\n",
      " -0.7878\n",
      "  0.1193\n",
      "  2.1392\n",
      " -1.7692\n",
      " -2.4428\n",
      "  0.5469\n",
      "  0.2205\n",
      " -2.1635\n",
      "  2.5527\n",
      " -1.7812\n",
      "  2.8137\n",
      " -1.4976\n",
      " -0.5588\n",
      " -1.0790\n",
      " -1.4959\n",
      "  2.5203\n",
      "  0.5884\n",
      "  0.3968\n",
      " -1.9673\n",
      " -1.3309\n",
      " -2.2384\n",
      "  0.4607\n",
      " -2.7603\n",
      " -1.1987\n",
      " -1.5756\n",
      " -0.7233\n",
      " -0.1288\n",
      "  1.8456\n",
      "  1.0032\n",
      " -0.8076\n",
      " -2.2443\n",
      " -2.3058\n",
      " -1.6318\n",
      " -0.8750\n",
      "  0.1822\n",
      "  2.4554\n",
      "  2.5985\n",
      "  1.3435\n",
      " -2.6448\n",
      " -0.3680\n",
      "  0.5195\n",
      "  2.5455\n",
      " -2.8322\n",
      "  0.0817\n",
      "  0.4975\n",
      " -1.4621\n",
      "  0.4231\n",
      "  2.7672\n",
      " -2.6462\n",
      "  2.4460\n",
      "  2.7612\n",
      " -1.7112\n",
      " -1.8154\n",
      "  1.3820\n",
      " -2.6151\n",
      " -2.8764\n",
      " -1.5311\n",
      " -0.5568\n",
      " -2.4369\n",
      "  1.2393\n",
      " -0.6524\n",
      " -0.6687\n",
      " -1.9025\n",
      " -2.6567\n",
      "  0.4169\n",
      "  2.8202\n",
      "  1.5362\n",
      "  0.2450\n",
      " -1.2413\n",
      " -2.2398\n",
      " -1.9720\n",
      " -1.2340\n",
      " -0.4965\n",
      "  0.7658\n",
      "  0.8110\n",
      " -2.6980\n",
      "  0.9144\n",
      " -0.1832\n",
      " -1.2262\n",
      "  2.8294\n",
      "  2.5920\n",
      " -2.1257\n",
      "  2.5346\n",
      "  1.7099\n",
      " -1.6896\n",
      "  0.6333\n",
      "  1.9151\n",
      " -0.8252\n",
      " -0.1354\n",
      " -1.0984\n",
      " -1.2963\n",
      " -0.0798\n",
      " -1.1799\n",
      "  1.3181\n",
      " -0.8692\n",
      "  1.2533\n",
      " -1.8349\n",
      "  0.7036\n",
      "  2.4500\n",
      "  0.4193\n",
      "  2.6868\n",
      " -0.4285\n",
      "  0.7669\n",
      " -2.2642\n",
      "  1.0772\n",
      " -2.8630\n",
      " -2.0189\n",
      " -1.8579\n",
      "  1.7974\n",
      "  2.3557\n",
      "  0.5236\n",
      " -1.1416\n",
      "  2.7245\n",
      " -0.2404\n",
      " -0.1267\n",
      "  0.8533\n",
      " -1.8574\n",
      " -2.8074\n",
      "  1.6599\n",
      "  0.4732\n",
      " -1.0769\n",
      "  2.1170\n",
      " -0.6714\n",
      "  1.7732\n",
      " -2.2913\n",
      "  0.3071\n",
      " -0.3257\n",
      "  2.1599\n",
      " -0.1032\n",
      " -1.7097\n",
      "  1.4182\n",
      " -1.0211\n",
      " -1.8558\n",
      " -1.1916\n",
      " -1.2387\n",
      "  1.1637\n",
      " -2.2506\n",
      "  1.2580\n",
      "  0.9350\n",
      "  1.3514\n",
      "  2.2999\n",
      " -0.2872\n",
      " -2.9016\n",
      "  1.8115\n",
      "  0.1862\n",
      " -2.1712\n",
      "  1.8501\n",
      " -0.0100\n",
      "  0.4625\n",
      " -1.4609\n",
      "  1.4623\n",
      " -1.9797\n",
      " -0.7748\n",
      "  2.0944\n",
      " -2.7859\n",
      "  1.4547\n",
      " -2.1804\n",
      "  1.2929\n",
      "  1.1469\n",
      "  0.8371\n",
      "  0.0167\n",
      "  1.5981\n",
      " -1.3573\n",
      "  2.3303\n",
      "  0.2925\n",
      "  0.3163\n",
      " -2.3230\n",
      " -1.5041\n",
      " -1.6435\n",
      "  1.7507\n",
      "  0.3562\n",
      "  1.9607\n",
      "  0.6453\n",
      "  0.4545\n",
      " -0.8111\n",
      " -1.3731\n",
      "  0.7148\n",
      " -2.0567\n",
      "  0.8467\n",
      "  1.1538\n",
      " -2.8514\n",
      " -1.5009\n",
      "  1.8969\n",
      " -0.9237\n",
      "  0.5911\n",
      "  0.8412\n",
      " -1.3525\n",
      " -0.7087\n",
      " -1.0521\n",
      "  0.0472\n",
      "  2.1365\n",
      " -1.2818\n",
      "  0.5868\n",
      "  1.4284\n",
      " -0.2731\n",
      " -1.9955\n",
      "  1.1027\n",
      "  2.3571\n",
      " -1.6670\n",
      "  1.4443\n",
      " -2.6855\n",
      " -0.3654\n",
      "  2.3780\n",
      "  0.5545\n",
      "  2.8766\n",
      " -1.2063\n",
      " -0.9699\n",
      " -2.4225\n",
      " -0.3016\n",
      "  1.9855\n",
      "  2.5847\n",
      " -0.3381\n",
      " -0.7558\n",
      "  0.1239\n",
      " -1.9697\n",
      " -2.0277\n",
      " -1.9125\n",
      "  1.2988\n",
      "  2.1537\n",
      " -0.7226\n",
      " -1.3231\n",
      "  2.0702\n",
      "  2.3913\n",
      " -1.0661\n",
      "  0.6462\n",
      "  1.5923\n",
      "  0.9049\n",
      "  1.0590\n",
      " -1.3156\n",
      " -1.3833\n",
      "  2.8467\n",
      "  0.8259\n",
      " -1.9753\n",
      "  2.2122\n",
      "  1.1434\n",
      "  0.8326\n",
      "  2.4146\n",
      " -1.3260\n",
      "[torch.FloatTensor of size 256]\n",
      "\n",
      "Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  1.2377e-02\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  4.5351e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  1.0595e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,253,.,.) = \n",
      "  6.1112e-02\n",
      "\n",
      "( 0 ,254,.,.) = \n",
      "  2.8637e-02\n",
      "\n",
      "( 0 ,255,.,.) = \n",
      " -4.6966e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  2.7671e-03\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      " -3.4273e-02\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      " -4.0710e-02\n",
      "    ... \n",
      "\n",
      "( 1 ,253,.,.) = \n",
      "  5.4983e-02\n",
      "\n",
      "( 1 ,254,.,.) = \n",
      "  3.7086e-02\n",
      "\n",
      "( 1 ,255,.,.) = \n",
      " -1.9530e-03\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      " -4.3775e-02\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  2.3624e-02\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  2.9282e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,253,.,.) = \n",
      "  5.8894e-02\n",
      "\n",
      "( 2 ,254,.,.) = \n",
      "  1.9950e-02\n",
      "\n",
      "( 2 ,255,.,.) = \n",
      " -4.5522e-02\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(253, 0 ,.,.) = \n",
      "  3.4603e-02\n",
      "\n",
      "(253, 1 ,.,.) = \n",
      "  1.0810e-02\n",
      "\n",
      "(253, 2 ,.,.) = \n",
      "  1.9132e-02\n",
      "    ... \n",
      "\n",
      "(253,253,.,.) = \n",
      "  1.0217e-02\n",
      "\n",
      "(253,254,.,.) = \n",
      " -5.1871e-02\n",
      "\n",
      "(253,255,.,.) = \n",
      "  2.5331e-02\n",
      "      ⋮  \n",
      "\n",
      "(254, 0 ,.,.) = \n",
      "  8.4278e-03\n",
      "\n",
      "(254, 1 ,.,.) = \n",
      " -5.0739e-02\n",
      "\n",
      "(254, 2 ,.,.) = \n",
      "  4.4941e-02\n",
      "    ... \n",
      "\n",
      "(254,253,.,.) = \n",
      "  2.8733e-03\n",
      "\n",
      "(254,254,.,.) = \n",
      " -3.6980e-02\n",
      "\n",
      "(254,255,.,.) = \n",
      "  4.4779e-02\n",
      "      ⋮  \n",
      "\n",
      "(255, 0 ,.,.) = \n",
      " -5.6194e-03\n",
      "\n",
      "(255, 1 ,.,.) = \n",
      "  6.2037e-02\n",
      "\n",
      "(255, 2 ,.,.) = \n",
      " -2.8097e-03\n",
      "    ... \n",
      "\n",
      "(255,253,.,.) = \n",
      "  4.9492e-02\n",
      "\n",
      "(255,254,.,.) = \n",
      "  4.2629e-02\n",
      "\n",
      "(255,255,.,.) = \n",
      "  2.0964e-02\n",
      "[torch.FloatTensor of size 256x256x1x1]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "  5.7942\n",
      "  3.3899\n",
      " -0.6196\n",
      " -4.9780\n",
      " -5.2975\n",
      " -5.4936\n",
      " -4.2101\n",
      " -4.7253\n",
      "  2.3119\n",
      " -2.2062\n",
      " -0.0491\n",
      " -3.9913\n",
      " -3.3276\n",
      " -4.2452\n",
      " -3.7712\n",
      "  3.5277\n",
      "  0.5036\n",
      " -3.6677\n",
      " -1.5613\n",
      " -5.8891\n",
      "  2.1111\n",
      " -2.1100\n",
      " -4.7003\n",
      " -4.7821\n",
      " -6.1463\n",
      " -6.1513\n",
      " -5.1988\n",
      " -0.5328\n",
      "  2.8564\n",
      "  2.7564\n",
      "  2.1860\n",
      "  4.2237\n",
      "  5.7322\n",
      " -5.1202\n",
      "  5.6156\n",
      "  0.7747\n",
      " -0.5835\n",
      "  5.4565\n",
      "  4.4829\n",
      "  4.4394\n",
      " -5.6567\n",
      " -0.6319\n",
      " -2.0814\n",
      " -0.0846\n",
      "  2.4261\n",
      " -3.1721\n",
      " -4.9446\n",
      "  3.2571\n",
      "  3.5095\n",
      "  4.5550\n",
      " -2.2136\n",
      "  5.6760\n",
      " -4.0963\n",
      "  2.7601\n",
      "  1.0089\n",
      "  4.4274\n",
      " -6.0744\n",
      " -4.4738\n",
      "  0.5195\n",
      " -0.5010\n",
      "  3.0758\n",
      "  1.0833\n",
      " -2.7826\n",
      " -3.9001\n",
      " -2.8198\n",
      "  5.8624\n",
      "  5.7356\n",
      " -3.7363\n",
      "  3.4983\n",
      " -2.4359\n",
      " -3.8761\n",
      "  0.7062\n",
      " -0.4320\n",
      " -3.7843\n",
      "  2.2854\n",
      " -4.5139\n",
      " -3.6997\n",
      " -2.1512\n",
      " -5.0882\n",
      " -4.3384\n",
      "  0.4188\n",
      "  3.5156\n",
      " -3.4257\n",
      "  5.7758\n",
      "  5.7179\n",
      "  2.7557\n",
      " -4.5854\n",
      "  1.5352\n",
      " -0.1164\n",
      "  0.3754\n",
      " -0.6923\n",
      " -4.0242\n",
      " -2.3380\n",
      " -0.3054\n",
      "  2.9261\n",
      "  5.5921\n",
      " -5.5639\n",
      " -0.9685\n",
      " -1.6440\n",
      " -3.9955\n",
      "  0.0611\n",
      "  5.6832\n",
      " -2.9719\n",
      "  4.8819\n",
      "  0.4130\n",
      "  3.3445\n",
      "  3.1670\n",
      "  0.1652\n",
      "  2.1965\n",
      " -2.5789\n",
      " -0.9417\n",
      " -2.9666\n",
      "  4.6798\n",
      " -1.9579\n",
      " -3.9787\n",
      " -4.5773\n",
      "  2.2752\n",
      "  4.5726\n",
      " -3.3084\n",
      "  3.0704\n",
      "  1.4616\n",
      "  4.3184\n",
      " -2.7657\n",
      "  2.0112\n",
      " -3.1917\n",
      " -2.1094\n",
      " -0.2605\n",
      "  0.4766\n",
      " -1.1162\n",
      "  5.0827\n",
      " -3.3623\n",
      "  1.1585\n",
      "  0.9951\n",
      "  5.0525\n",
      "  4.8379\n",
      " -0.2377\n",
      "  2.3589\n",
      "  2.7472\n",
      "  0.5211\n",
      " -4.0339\n",
      "  2.4941\n",
      "  0.9838\n",
      " -3.0659\n",
      "  3.5636\n",
      " -5.5573\n",
      " -3.8837\n",
      " -6.2159\n",
      "  6.1902\n",
      " -4.2703\n",
      " -3.4785\n",
      "  0.7098\n",
      " -3.6400\n",
      "  3.7032\n",
      " -6.2133\n",
      "  4.3776\n",
      "  3.8339\n",
      "  6.1910\n",
      "  3.8675\n",
      "  0.6710\n",
      " -3.5206\n",
      " -3.1693\n",
      "  3.5349\n",
      " -3.9181\n",
      " -3.9680\n",
      " -2.0672\n",
      " -5.4296\n",
      " -1.7759\n",
      "  4.1174\n",
      "  5.8947\n",
      " -0.4810\n",
      "  6.1121\n",
      " -1.6298\n",
      "  0.6863\n",
      "  3.7108\n",
      " -3.5861\n",
      "  6.0212\n",
      " -0.0583\n",
      " -1.3384\n",
      "  2.5752\n",
      " -2.3092\n",
      "  6.0604\n",
      "  3.8712\n",
      "  3.1936\n",
      "  2.3540\n",
      "  2.9634\n",
      "  3.3609\n",
      "  0.8157\n",
      "  1.0732\n",
      "  1.5348\n",
      "  1.7038\n",
      "  5.3389\n",
      " -3.5667\n",
      " -5.4375\n",
      " -3.6614\n",
      " -0.5764\n",
      "  1.9955\n",
      "  0.0237\n",
      "  2.7898\n",
      " -3.4762\n",
      "  1.2585\n",
      " -0.5991\n",
      "  1.5944\n",
      "  1.1565\n",
      " -3.4352\n",
      " -5.4305\n",
      "  4.6943\n",
      "  0.4815\n",
      " -2.7607\n",
      "  2.7418\n",
      "  1.4573\n",
      " -0.5480\n",
      "  1.8942\n",
      " -2.2293\n",
      "  2.3215\n",
      "  2.2409\n",
      " -5.8685\n",
      "  1.6776\n",
      "  5.4242\n",
      "  1.4837\n",
      " -3.1005\n",
      "  2.3771\n",
      "  5.9178\n",
      "  0.2276\n",
      "  4.5834\n",
      " -2.2094\n",
      "  5.3040\n",
      "  0.6514\n",
      " -1.7283\n",
      " -1.9552\n",
      " -3.7312\n",
      "  5.0150\n",
      " -1.8892\n",
      "  4.4817\n",
      "  5.6184\n",
      " -5.1346\n",
      "  2.6305\n",
      "  1.5972\n",
      "  0.5608\n",
      " -4.0258\n",
      "  1.3790\n",
      " -2.3751\n",
      " -3.0068\n",
      " -2.9994\n",
      "  2.3315\n",
      " -5.7021\n",
      "  5.0641\n",
      "  0.1108\n",
      " -4.3684\n",
      "  3.3412\n",
      "  4.0263\n",
      " -5.6073\n",
      " -5.2790\n",
      "  5.5968\n",
      " -4.2437\n",
      "  5.5267\n",
      "  3.5595\n",
      "[torch.FloatTensor of size 256]\n",
      "\n",
      "Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  8.9710e-03 -2.5261e-03  1.3207e-02\n",
      "  5.8111e-03 -1.9017e-02  1.7783e-02\n",
      "  1.0697e-02 -1.5644e-02  1.9995e-02\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      " -3.0391e-03 -9.8244e-03  1.4433e-03\n",
      " -1.8724e-02  3.7545e-03 -1.7767e-02\n",
      " -1.8879e-02 -1.8136e-02  1.8549e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      " -1.5561e-02 -2.0646e-02 -7.1178e-03\n",
      "  8.0683e-03 -5.0886e-04 -1.7080e-02\n",
      "  1.0137e-02  8.7912e-03  1.7822e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,253,.,.) = \n",
      " -1.3409e-03 -1.1658e-02  1.2803e-03\n",
      "  1.9272e-02  8.3607e-03 -1.7453e-02\n",
      "  1.0243e-03 -1.1573e-02 -1.9080e-02\n",
      "\n",
      "( 0 ,254,.,.) = \n",
      " -4.4501e-03  1.7219e-02 -1.9616e-03\n",
      " -1.3948e-03 -1.1843e-02 -9.7953e-03\n",
      "  1.2631e-03 -1.4348e-02 -2.0371e-04\n",
      "\n",
      "( 0 ,255,.,.) = \n",
      "  1.6227e-02  1.3752e-02 -9.5437e-04\n",
      "  5.2485e-03  1.0412e-03  1.9884e-02\n",
      " -1.6305e-04  1.2386e-02  1.0270e-02\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  8.8334e-03 -1.2098e-02  1.7497e-02\n",
      " -1.8975e-02  1.1644e-02  1.6775e-02\n",
      " -7.5982e-03  1.5872e-02  1.8157e-02\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      " -1.1812e-02  1.1630e-02 -2.8710e-03\n",
      "  1.9483e-02  1.2588e-03 -9.7133e-03\n",
      "  7.2809e-04  1.3078e-02 -1.5858e-02\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      " -5.2004e-03  1.0590e-02 -1.9273e-02\n",
      " -1.5972e-03 -1.2949e-02 -1.5928e-02\n",
      "  1.2771e-02 -1.8786e-02  2.4682e-03\n",
      "    ... \n",
      "\n",
      "( 1 ,253,.,.) = \n",
      " -1.3160e-02  6.1334e-03 -5.1375e-03\n",
      " -1.9952e-02  4.1400e-03 -9.9138e-03\n",
      "  5.0760e-03  2.0116e-02 -5.3181e-03\n",
      "\n",
      "( 1 ,254,.,.) = \n",
      " -4.6407e-03  9.6251e-03 -1.9486e-02\n",
      " -1.5243e-02 -9.4090e-03 -3.1727e-03\n",
      "  3.7211e-03  5.2554e-03  9.1198e-03\n",
      "\n",
      "( 1 ,255,.,.) = \n",
      "  7.0021e-04  1.6877e-02 -1.7458e-02\n",
      "  1.9083e-03 -1.6441e-02  4.3848e-03\n",
      " -8.4431e-03 -1.6066e-02 -1.8437e-02\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      " -1.8014e-02  1.1984e-02 -3.5197e-04\n",
      "  1.7206e-02  1.6167e-02  2.3749e-03\n",
      "  5.2765e-03  1.8720e-02 -6.1669e-03\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      "  2.2980e-03  8.6196e-03  1.5378e-02\n",
      "  1.1022e-02  9.7718e-03 -1.8812e-02\n",
      " -1.6499e-02 -1.8469e-02 -8.8641e-03\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      "  9.7310e-04 -7.8786e-03  1.2072e-02\n",
      "  1.3867e-02 -1.8498e-02  1.5550e-02\n",
      " -6.6267e-03 -1.0776e-02 -2.0205e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,253,.,.) = \n",
      "  1.4884e-02 -1.3822e-02  4.8967e-03\n",
      " -1.9863e-02  1.5779e-04  1.3054e-02\n",
      "  5.2676e-04  3.4851e-03  1.4355e-02\n",
      "\n",
      "( 2 ,254,.,.) = \n",
      "  1.5791e-03  1.3696e-02  9.4259e-03\n",
      "  1.2778e-02 -7.0175e-03 -1.3962e-04\n",
      "  1.1368e-02  5.5881e-03  1.2416e-02\n",
      "\n",
      "( 2 ,255,.,.) = \n",
      " -1.3958e-02 -9.6219e-05  1.4507e-02\n",
      "  1.2239e-02 -7.5547e-03  1.9284e-02\n",
      " -1.2530e-02 -8.3615e-03  1.5124e-02\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(509, 0 ,.,.) = \n",
      " -1.6430e-02 -2.9960e-03  1.9681e-03\n",
      " -3.5436e-03 -1.5833e-02 -1.8704e-03\n",
      " -1.3546e-02 -8.0772e-03  3.0675e-03\n",
      "\n",
      "(509, 1 ,.,.) = \n",
      "  2.0076e-02 -9.1413e-03  1.0096e-02\n",
      " -2.5963e-03  1.7954e-03  1.6238e-02\n",
      "  1.4297e-02 -1.3765e-06  1.3394e-02\n",
      "\n",
      "(509, 2 ,.,.) = \n",
      " -1.7330e-02 -1.0231e-03 -1.6907e-02\n",
      " -4.1825e-03 -1.9897e-02 -1.3350e-02\n",
      " -9.7428e-03  1.9194e-02  2.1598e-03\n",
      "    ... \n",
      "\n",
      "(509,253,.,.) = \n",
      "  6.8549e-03 -9.5380e-03 -1.7446e-03\n",
      " -1.7853e-02 -1.0985e-02  7.7754e-03\n",
      "  1.1648e-02 -1.1179e-02 -1.4999e-02\n",
      "\n",
      "(509,254,.,.) = \n",
      " -6.3989e-03 -1.6783e-02  1.6569e-02\n",
      " -3.4269e-03  5.8365e-03  2.0709e-02\n",
      " -1.2785e-02 -9.6992e-03 -1.4649e-02\n",
      "\n",
      "(509,255,.,.) = \n",
      "  1.4262e-02 -1.6594e-02  5.3022e-03\n",
      " -1.4628e-02 -1.1100e-02  1.3477e-02\n",
      " -1.7745e-02  2.7158e-03 -1.1234e-02\n",
      "      ⋮  \n",
      "\n",
      "(510, 0 ,.,.) = \n",
      "  2.6066e-03 -8.0225e-03 -1.4507e-02\n",
      " -1.6738e-02  1.9045e-03 -1.6314e-02\n",
      "  8.1251e-04 -1.3393e-02  1.0034e-02\n",
      "\n",
      "(510, 1 ,.,.) = \n",
      " -1.4849e-02  1.5112e-02 -7.7866e-03\n",
      " -1.9637e-02  1.8883e-02 -7.2329e-03\n",
      " -1.3419e-02  1.8696e-02  1.8183e-02\n",
      "\n",
      "(510, 2 ,.,.) = \n",
      " -8.0955e-03  3.1948e-03  1.3665e-02\n",
      "  5.0760e-04  1.4137e-02  1.6573e-02\n",
      " -1.6251e-02 -1.0815e-02 -6.0048e-03\n",
      "    ... \n",
      "\n",
      "(510,253,.,.) = \n",
      "  1.3997e-02 -1.2007e-03  1.0885e-02\n",
      "  1.2609e-02  8.3412e-03  1.9239e-02\n",
      "  8.3447e-04  3.7394e-04  4.6407e-03\n",
      "\n",
      "(510,254,.,.) = \n",
      "  1.0254e-02 -7.4478e-04 -1.9994e-02\n",
      " -2.0010e-02  6.8665e-03  6.3243e-03\n",
      "  1.0138e-02  1.0747e-03  1.1295e-02\n",
      "\n",
      "(510,255,.,.) = \n",
      "  3.7858e-03  1.9911e-02  1.5559e-02\n",
      "  1.6902e-02  5.5396e-03 -1.4086e-02\n",
      " -1.5686e-02  1.4090e-02 -1.7567e-02\n",
      "      ⋮  \n",
      "\n",
      "(511, 0 ,.,.) = \n",
      "  1.7706e-02  1.6529e-02  9.2169e-03\n",
      "  6.2068e-03 -1.2661e-02 -4.5167e-03\n",
      " -1.3853e-02 -1.3764e-02  1.8971e-02\n",
      "\n",
      "(511, 1 ,.,.) = \n",
      " -4.6718e-03  1.1835e-02  9.6728e-03\n",
      " -1.5803e-02  4.6864e-03  9.8946e-05\n",
      " -1.7804e-03  1.3688e-03  1.7302e-02\n",
      "\n",
      "(511, 2 ,.,.) = \n",
      " -1.5690e-02  4.0338e-03  1.5282e-03\n",
      "  1.3645e-02 -8.2148e-03 -7.6354e-03\n",
      " -1.8800e-03  8.8587e-03 -1.0926e-02\n",
      "    ... \n",
      "\n",
      "(511,253,.,.) = \n",
      "  1.3134e-02  4.9017e-03 -1.7009e-02\n",
      " -1.5466e-02 -4.6913e-03 -4.3018e-03\n",
      "  1.9552e-02 -1.7202e-02  1.2563e-02\n",
      "\n",
      "(511,254,.,.) = \n",
      " -1.5200e-02 -3.9539e-03 -3.3113e-03\n",
      " -4.9580e-03 -2.1766e-03 -1.1365e-02\n",
      " -3.8040e-03 -1.6226e-02 -2.0247e-02\n",
      "\n",
      "(511,255,.,.) = \n",
      "  1.7333e-02  1.0848e-02 -2.1091e-03\n",
      " -1.6704e-02 -1.3230e-02  1.1149e-02\n",
      "  1.8899e-02 -1.7110e-02 -1.7833e-02\n",
      "[torch.FloatTensor of size 512x256x3x3]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " -1.3846\n",
      "  0.9350\n",
      " -2.0200\n",
      " -1.8719\n",
      "  0.5321\n",
      "  1.0496\n",
      "  0.5406\n",
      "  1.0293\n",
      "  0.9107\n",
      "  0.9333\n",
      "  1.5760\n",
      "  1.3787\n",
      "  0.2922\n",
      " -0.9962\n",
      " -0.9882\n",
      "  0.0726\n",
      " -0.0791\n",
      "  0.4551\n",
      " -0.5452\n",
      "  1.7318\n",
      " -0.9462\n",
      " -0.3659\n",
      " -0.9625\n",
      "  0.0906\n",
      "  2.0112\n",
      " -1.1276\n",
      "  0.6138\n",
      "  0.4422\n",
      " -0.7517\n",
      " -0.7476\n",
      "  2.0374\n",
      " -1.5850\n",
      "  1.0336\n",
      " -1.8649\n",
      " -0.4753\n",
      "  0.5617\n",
      "  1.9621\n",
      " -1.1136\n",
      " -1.1128\n",
      " -1.3228\n",
      "  1.1531\n",
      "  0.5859\n",
      " -1.4635\n",
      "  1.6463\n",
      "  0.2865\n",
      " -1.7589\n",
      "  1.1671\n",
      "  0.5486\n",
      "  0.4886\n",
      "  1.9281\n",
      " -0.0281\n",
      " -0.2094\n",
      "  0.7516\n",
      "  0.9819\n",
      "  0.7569\n",
      " -1.4584\n",
      " -0.4304\n",
      " -0.7232\n",
      "  1.2758\n",
      " -1.1196\n",
      " -0.3453\n",
      " -0.0406\n",
      "  1.2678\n",
      " -1.6841\n",
      " -0.4744\n",
      " -0.9100\n",
      " -1.9727\n",
      "  0.8337\n",
      "  0.7334\n",
      "  1.7230\n",
      " -1.1097\n",
      "  0.8667\n",
      "  1.8746\n",
      "  1.0393\n",
      " -1.3258\n",
      "  1.4169\n",
      "  1.1937\n",
      "  1.4797\n",
      " -1.0497\n",
      "  0.2550\n",
      "  1.1236\n",
      " -0.9435\n",
      " -1.3208\n",
      "  1.5004\n",
      "  0.1768\n",
      "  1.8239\n",
      " -0.3724\n",
      "  1.7250\n",
      " -0.9827\n",
      "  0.4548\n",
      "  0.9844\n",
      " -1.7021\n",
      " -1.1002\n",
      "  0.1694\n",
      " -0.7207\n",
      " -0.6690\n",
      " -1.1689\n",
      "  0.9126\n",
      "  0.4917\n",
      " -0.1677\n",
      " -0.6244\n",
      " -0.7819\n",
      " -0.7126\n",
      " -0.5945\n",
      "  1.6477\n",
      " -0.8934\n",
      "  1.6333\n",
      "  0.9439\n",
      " -0.1315\n",
      "  1.4461\n",
      "  0.0155\n",
      "  0.2558\n",
      "  0.5697\n",
      "  1.7491\n",
      "  0.3303\n",
      "  1.1323\n",
      "  0.1483\n",
      " -1.4969\n",
      " -1.2074\n",
      " -1.1761\n",
      " -1.2031\n",
      " -0.1525\n",
      "  0.3461\n",
      " -0.8006\n",
      "  0.9812\n",
      " -2.0642\n",
      " -0.6695\n",
      "  0.0262\n",
      "  0.3193\n",
      " -2.0177\n",
      "  1.0607\n",
      "  0.3708\n",
      "  2.0471\n",
      " -0.0883\n",
      "  0.5562\n",
      "  0.6389\n",
      " -0.1553\n",
      " -2.0297\n",
      " -0.5488\n",
      " -0.7335\n",
      "  0.2984\n",
      "  1.4760\n",
      "  1.9479\n",
      " -1.8622\n",
      " -1.9300\n",
      "  1.2666\n",
      "  2.0756\n",
      " -1.6466\n",
      " -1.5209\n",
      "  1.1216\n",
      "  1.3315\n",
      "  1.4466\n",
      " -1.3758\n",
      "  0.9732\n",
      "  1.1882\n",
      "  0.1941\n",
      "  1.1173\n",
      "  1.4743\n",
      "  0.9184\n",
      "  0.7855\n",
      " -0.9911\n",
      " -1.6992\n",
      "  0.3969\n",
      " -1.8381\n",
      "  2.0235\n",
      "  0.3682\n",
      "  1.1655\n",
      " -2.0255\n",
      " -1.4762\n",
      "  0.3383\n",
      "  0.7666\n",
      " -0.7167\n",
      " -1.0527\n",
      " -0.3497\n",
      "  0.4091\n",
      " -1.4297\n",
      " -1.4714\n",
      "  2.0038\n",
      " -2.0604\n",
      "  0.3772\n",
      "  0.1148\n",
      " -0.5018\n",
      " -0.7623\n",
      "  0.9439\n",
      " -0.8669\n",
      " -0.2171\n",
      "  0.5027\n",
      "  1.3277\n",
      " -0.0395\n",
      " -0.4694\n",
      " -1.4858\n",
      "  1.2831\n",
      " -0.4546\n",
      "  1.2750\n",
      " -0.1645\n",
      " -1.6974\n",
      " -1.1710\n",
      " -1.5032\n",
      " -1.2376\n",
      " -1.4428\n",
      " -1.2590\n",
      "  2.0795\n",
      "  1.9477\n",
      "  0.5832\n",
      "  0.9783\n",
      "  1.3513\n",
      "  0.6311\n",
      " -1.1665\n",
      "  1.8057\n",
      "  1.0195\n",
      " -0.7305\n",
      " -1.8200\n",
      " -0.2278\n",
      "  1.3335\n",
      "  0.8840\n",
      "  1.2966\n",
      " -1.9394\n",
      "  1.1505\n",
      "  0.6022\n",
      "  0.6560\n",
      "  0.1074\n",
      "  1.2589\n",
      "  2.0762\n",
      " -1.8053\n",
      " -1.4680\n",
      "  1.0031\n",
      " -1.5911\n",
      "  1.2633\n",
      " -1.6292\n",
      "  0.2398\n",
      "  1.7242\n",
      "  0.7609\n",
      "  1.2900\n",
      "  0.9028\n",
      " -0.0242\n",
      "  0.0418\n",
      "  0.9477\n",
      "  0.4154\n",
      " -0.2927\n",
      "  0.2055\n",
      " -1.8136\n",
      " -1.8199\n",
      " -0.9507\n",
      "  0.1054\n",
      " -1.9836\n",
      "  0.2210\n",
      " -1.8946\n",
      "  0.9029\n",
      "  1.6032\n",
      " -0.6981\n",
      "  0.8870\n",
      "  1.0793\n",
      " -0.6843\n",
      "  1.2272\n",
      "  0.0521\n",
      " -0.1231\n",
      " -0.4633\n",
      "  0.4501\n",
      " -1.5549\n",
      "  0.8229\n",
      "  0.7373\n",
      "  0.7151\n",
      " -1.5785\n",
      " -1.7883\n",
      "  1.1643\n",
      " -1.4215\n",
      " -0.2161\n",
      " -0.7152\n",
      " -1.0546\n",
      "  1.2765\n",
      " -1.9773\n",
      " -0.6214\n",
      " -0.1314\n",
      "  0.8541\n",
      " -1.3030\n",
      " -1.3779\n",
      " -0.4944\n",
      " -0.9060\n",
      " -0.4162\n",
      "  0.5145\n",
      " -0.5438\n",
      "  1.9687\n",
      "  0.6920\n",
      " -1.9774\n",
      " -0.7254\n",
      " -0.4300\n",
      "  0.7175\n",
      " -0.0040\n",
      " -1.5964\n",
      "  0.1380\n",
      " -1.3268\n",
      "  1.1901\n",
      "  1.1263\n",
      " -0.5197\n",
      "  1.3709\n",
      "  1.6765\n",
      " -1.1230\n",
      " -0.2176\n",
      " -1.0507\n",
      "  0.7937\n",
      " -1.3111\n",
      "  1.9069\n",
      " -1.5722\n",
      " -1.9376\n",
      " -1.2098\n",
      "  0.1465\n",
      "  1.8425\n",
      "  1.3365\n",
      "  0.3926\n",
      "  0.5266\n",
      " -1.2502\n",
      "  0.0814\n",
      "  0.3081\n",
      " -1.7556\n",
      "  1.2157\n",
      "  1.9413\n",
      " -1.6439\n",
      " -1.4882\n",
      " -1.0609\n",
      " -1.6541\n",
      " -0.8966\n",
      "  0.0736\n",
      " -1.8776\n",
      " -0.2254\n",
      "  1.9027\n",
      "  0.2866\n",
      " -2.0768\n",
      "  1.5921\n",
      " -0.2513\n",
      "  1.7854\n",
      " -1.3264\n",
      " -0.8853\n",
      "  1.2993\n",
      "  0.9002\n",
      " -1.0027\n",
      " -0.7225\n",
      " -1.7400\n",
      " -0.4145\n",
      " -0.8861\n",
      "  1.4062\n",
      " -1.6664\n",
      " -0.7842\n",
      "  0.3462\n",
      "  1.0005\n",
      " -0.0879\n",
      " -1.6160\n",
      " -0.0507\n",
      "  1.2041\n",
      "  0.0823\n",
      " -0.3483\n",
      " -1.5549\n",
      " -1.8412\n",
      "  1.0191\n",
      "  0.4819\n",
      "  0.1937\n",
      "  0.9394\n",
      " -0.1359\n",
      "  1.5414\n",
      "  1.2920\n",
      "  1.2119\n",
      " -1.7593\n",
      " -0.8907\n",
      " -0.2171\n",
      "  1.9810\n",
      " -1.4274\n",
      " -0.1805\n",
      " -1.5829\n",
      "  0.3506\n",
      " -1.0070\n",
      "  0.8825\n",
      " -0.8492\n",
      "  1.7489\n",
      "  0.6079\n",
      " -0.9947\n",
      "  0.8595\n",
      " -0.4484\n",
      " -0.2268\n",
      " -0.2809\n",
      "  1.5233\n",
      "  0.6388\n",
      " -0.7789\n",
      " -0.7012\n",
      " -0.0244\n",
      " -0.3755\n",
      " -1.8764\n",
      "  0.3421\n",
      " -0.2190\n",
      " -1.4841\n",
      " -0.6597\n",
      "  1.6344\n",
      "  1.1922\n",
      " -0.1266\n",
      " -1.8124\n",
      " -0.4070\n",
      "  0.4104\n",
      " -1.6036\n",
      "  1.6149\n",
      "  1.4194\n",
      " -1.7054\n",
      " -1.3494\n",
      " -1.5642\n",
      "  1.8975\n",
      " -1.3845\n",
      " -1.0970\n",
      "  1.4128\n",
      " -0.7440\n",
      " -0.1473\n",
      "  0.0505\n",
      " -1.3330\n",
      "  1.0242\n",
      "  0.4492\n",
      " -0.6978\n",
      "  0.8361\n",
      "  0.4515\n",
      " -1.1310\n",
      " -1.0660\n",
      "  2.0426\n",
      "  0.6667\n",
      " -0.1760\n",
      " -1.6904\n",
      " -1.1380\n",
      " -1.3897\n",
      "  1.6671\n",
      "  0.5260\n",
      " -0.1952\n",
      "  0.4986\n",
      " -1.8144\n",
      " -0.0374\n",
      " -0.0008\n",
      " -0.6867\n",
      " -0.4511\n",
      "  1.2270\n",
      " -1.8649\n",
      " -0.8886\n",
      " -0.6506\n",
      " -0.2699\n",
      " -0.6709\n",
      "  0.7357\n",
      "  1.3730\n",
      "  0.2940\n",
      " -0.8441\n",
      "  1.2450\n",
      " -1.8447\n",
      "  1.2969\n",
      "  0.0970\n",
      " -2.0004\n",
      " -0.4852\n",
      "  0.5752\n",
      " -0.9404\n",
      "  0.3188\n",
      "  1.2635\n",
      "  2.0624\n",
      " -0.2845\n",
      " -1.4390\n",
      "  1.4497\n",
      " -0.5675\n",
      " -1.3798\n",
      "  0.5699\n",
      "  2.0454\n",
      " -1.5188\n",
      "  0.3586\n",
      " -1.6051\n",
      " -1.4943\n",
      " -0.0416\n",
      "  0.6707\n",
      "  1.0946\n",
      "  0.6461\n",
      " -1.4007\n",
      " -1.1494\n",
      "  1.9451\n",
      " -0.0840\n",
      " -1.6399\n",
      "  0.4502\n",
      " -1.5639\n",
      " -0.5391\n",
      "  0.5481\n",
      " -0.8428\n",
      " -0.0658\n",
      "  1.6972\n",
      " -0.2296\n",
      " -0.0102\n",
      " -0.9707\n",
      " -2.0781\n",
      " -0.0365\n",
      " -0.3930\n",
      " -1.1089\n",
      "  2.0784\n",
      "  1.3315\n",
      "  1.0448\n",
      " -0.8114\n",
      " -0.2584\n",
      " -0.9288\n",
      "  1.5500\n",
      " -0.9291\n",
      " -0.3813\n",
      "  1.0003\n",
      "  0.9483\n",
      "  1.9329\n",
      "  1.5892\n",
      "  1.7264\n",
      " -1.6399\n",
      " -1.1147\n",
      "  1.2059\n",
      " -1.0382\n",
      "  0.7619\n",
      " -0.5372\n",
      "  0.0238\n",
      " -1.3642\n",
      "  0.3754\n",
      " -0.6490\n",
      "  1.3277\n",
      "  1.5215\n",
      "[torch.FloatTensor of size 512]\n",
      "\n",
      "Parameter containing:\n",
      "( 0 , 0 ,.,.) = \n",
      "  3.8810e-02\n",
      "\n",
      "( 0 , 1 ,.,.) = \n",
      "  3.8138e-02\n",
      "\n",
      "( 0 , 2 ,.,.) = \n",
      "  1.1812e-02\n",
      "    ... \n",
      "\n",
      "( 0 ,509,.,.) = \n",
      "  4.1821e-02\n",
      "\n",
      "( 0 ,510,.,.) = \n",
      " -1.2508e-02\n",
      "\n",
      "( 0 ,511,.,.) = \n",
      " -7.0348e-03\n",
      "      ⋮  \n",
      "\n",
      "( 1 , 0 ,.,.) = \n",
      "  2.5730e-02\n",
      "\n",
      "( 1 , 1 ,.,.) = \n",
      "  2.4798e-02\n",
      "\n",
      "( 1 , 2 ,.,.) = \n",
      " -2.4435e-02\n",
      "    ... \n",
      "\n",
      "( 1 ,509,.,.) = \n",
      " -3.8468e-03\n",
      "\n",
      "( 1 ,510,.,.) = \n",
      " -4.5985e-03\n",
      "\n",
      "( 1 ,511,.,.) = \n",
      " -1.5116e-02\n",
      "      ⋮  \n",
      "\n",
      "( 2 , 0 ,.,.) = \n",
      " -6.1652e-04\n",
      "\n",
      "( 2 , 1 ,.,.) = \n",
      " -1.9807e-02\n",
      "\n",
      "( 2 , 2 ,.,.) = \n",
      " -2.7826e-02\n",
      "    ... \n",
      "\n",
      "( 2 ,509,.,.) = \n",
      " -3.8353e-02\n",
      "\n",
      "( 2 ,510,.,.) = \n",
      " -3.3994e-02\n",
      "\n",
      "( 2 ,511,.,.) = \n",
      "  1.8055e-02\n",
      "...     \n",
      "      ⋮  \n",
      "\n",
      "(509, 0 ,.,.) = \n",
      " -9.3248e-03\n",
      "\n",
      "(509, 1 ,.,.) = \n",
      "  4.4102e-02\n",
      "\n",
      "(509, 2 ,.,.) = \n",
      "  2.4003e-02\n",
      "    ... \n",
      "\n",
      "(509,509,.,.) = \n",
      " -8.9130e-03\n",
      "\n",
      "(509,510,.,.) = \n",
      " -5.8657e-04\n",
      "\n",
      "(509,511,.,.) = \n",
      "  8.3701e-03\n",
      "      ⋮  \n",
      "\n",
      "(510, 0 ,.,.) = \n",
      "  3.6707e-02\n",
      "\n",
      "(510, 1 ,.,.) = \n",
      " -3.1095e-02\n",
      "\n",
      "(510, 2 ,.,.) = \n",
      " -3.4513e-02\n",
      "    ... \n",
      "\n",
      "(510,509,.,.) = \n",
      " -6.5450e-03\n",
      "\n",
      "(510,510,.,.) = \n",
      "  1.8369e-03\n",
      "\n",
      "(510,511,.,.) = \n",
      "  4.2753e-02\n",
      "      ⋮  \n",
      "\n",
      "(511, 0 ,.,.) = \n",
      "  3.2729e-02\n",
      "\n",
      "(511, 1 ,.,.) = \n",
      "  5.2820e-03\n",
      "\n",
      "(511, 2 ,.,.) = \n",
      " -2.6193e-02\n",
      "    ... \n",
      "\n",
      "(511,509,.,.) = \n",
      "  7.6782e-03\n",
      "\n",
      "(511,510,.,.) = \n",
      "  2.2817e-02\n",
      "\n",
      "(511,511,.,.) = \n",
      " -3.2246e-02\n",
      "[torch.FloatTensor of size 512x512x1x1]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " -4.0373\n",
      " -3.2818\n",
      " -4.2165\n",
      "  4.1850\n",
      "  0.1912\n",
      "  0.4079\n",
      " -4.1771\n",
      " -0.7532\n",
      "  3.5257\n",
      "  3.7175\n",
      "  0.7909\n",
      " -1.4864\n",
      " -3.8082\n",
      "  2.1935\n",
      " -3.7671\n",
      "  0.9782\n",
      "  3.8109\n",
      " -2.3908\n",
      " -2.7588\n",
      "  0.9689\n",
      " -0.2250\n",
      " -1.2756\n",
      "  0.4281\n",
      "  1.9579\n",
      "  1.8149\n",
      " -0.0944\n",
      "  3.2062\n",
      "  0.9247\n",
      "  2.9139\n",
      " -3.3428\n",
      " -1.4870\n",
      " -3.8728\n",
      " -3.9307\n",
      "  0.0088\n",
      " -0.1791\n",
      "  1.9085\n",
      "  2.5940\n",
      "  0.6116\n",
      " -1.0608\n",
      " -0.1884\n",
      " -0.0253\n",
      "  1.8743\n",
      " -0.1231\n",
      "  0.2267\n",
      "  1.0704\n",
      " -4.0033\n",
      " -0.7277\n",
      "  0.5495\n",
      " -2.7401\n",
      " -2.2912\n",
      " -2.9873\n",
      "  1.5610\n",
      " -2.1629\n",
      "  3.4797\n",
      " -0.8280\n",
      "  3.1506\n",
      " -3.0790\n",
      " -2.8322\n",
      " -0.7549\n",
      " -4.0507\n",
      " -1.7541\n",
      "  0.5103\n",
      " -0.4126\n",
      " -4.1247\n",
      " -1.6109\n",
      " -1.6914\n",
      " -3.5920\n",
      "  0.1513\n",
      "  0.1396\n",
      "  2.1500\n",
      "  0.7946\n",
      " -1.4876\n",
      " -1.6350\n",
      "  1.8981\n",
      "  2.6058\n",
      " -0.8708\n",
      " -0.7161\n",
      " -1.1945\n",
      "  1.1789\n",
      "  3.4145\n",
      " -0.8390\n",
      "  3.1680\n",
      " -3.0574\n",
      "  1.2980\n",
      "  3.6047\n",
      " -0.4681\n",
      " -4.1686\n",
      "  1.1647\n",
      " -0.3272\n",
      " -2.6723\n",
      "  3.6163\n",
      " -2.2192\n",
      " -0.2562\n",
      " -2.6135\n",
      "  0.4860\n",
      "  1.6434\n",
      "  0.4327\n",
      "  3.8550\n",
      "  3.5356\n",
      " -1.8809\n",
      "  1.5025\n",
      "  3.9234\n",
      " -1.8307\n",
      "  1.4333\n",
      "  2.3640\n",
      "  4.3341\n",
      " -4.2627\n",
      "  2.3578\n",
      "  0.5536\n",
      " -0.5164\n",
      "  2.0817\n",
      "  4.3691\n",
      "  1.6303\n",
      " -0.7355\n",
      " -1.5055\n",
      "  2.0805\n",
      "  2.4934\n",
      " -1.0562\n",
      "  3.7647\n",
      " -3.6835\n",
      "  1.7357\n",
      " -1.3324\n",
      " -1.5837\n",
      " -3.9255\n",
      "  0.5290\n",
      "  3.5467\n",
      " -3.0239\n",
      " -0.9360\n",
      "  2.3664\n",
      "  1.1349\n",
      "  2.0739\n",
      "  2.7629\n",
      " -1.6794\n",
      "  1.1928\n",
      "  1.7846\n",
      " -3.5186\n",
      " -2.8238\n",
      " -2.5114\n",
      "  0.9378\n",
      "  2.5404\n",
      " -1.1534\n",
      " -2.8557\n",
      "  4.3893\n",
      " -2.4055\n",
      "  0.3875\n",
      "  1.6929\n",
      " -3.2100\n",
      " -1.8944\n",
      " -0.4333\n",
      "  3.5952\n",
      "  0.4820\n",
      " -2.1639\n",
      " -3.2299\n",
      " -1.0764\n",
      " -1.9293\n",
      " -3.1967\n",
      "  3.0600\n",
      " -2.6860\n",
      "  2.1821\n",
      "  4.0228\n",
      "  2.5267\n",
      "  2.0603\n",
      "  1.9861\n",
      "  0.6114\n",
      "  2.7325\n",
      "  2.0820\n",
      " -0.6475\n",
      " -3.5166\n",
      " -1.2907\n",
      " -3.0558\n",
      "  2.5203\n",
      " -2.2823\n",
      " -0.3224\n",
      " -1.8546\n",
      " -3.1485\n",
      "  3.9351\n",
      " -0.4097\n",
      " -2.8852\n",
      "  0.3994\n",
      "  0.6350\n",
      " -3.2747\n",
      "  0.0921\n",
      "  0.2441\n",
      " -0.6833\n",
      " -3.8540\n",
      "  4.1463\n",
      "  1.3589\n",
      " -1.6415\n",
      "  1.7537\n",
      "  3.2352\n",
      "  3.8847\n",
      "  3.1018\n",
      "  0.0096\n",
      "  2.3431\n",
      "  0.4632\n",
      "  1.8104\n",
      "  0.2329\n",
      " -3.3272\n",
      "  2.8684\n",
      " -1.9311\n",
      "  3.4561\n",
      "  3.1500\n",
      "  3.5239\n",
      "  2.2553\n",
      " -2.3222\n",
      "  0.6028\n",
      "  3.7552\n",
      "  2.0190\n",
      "  4.3893\n",
      " -1.3070\n",
      " -1.4328\n",
      " -2.1370\n",
      "  1.7758\n",
      " -1.1450\n",
      " -3.5176\n",
      "  2.2321\n",
      " -3.9618\n",
      " -3.2314\n",
      " -1.4232\n",
      "  2.9720\n",
      " -2.1496\n",
      " -1.6878\n",
      "  1.8848\n",
      "  0.1311\n",
      " -3.0410\n",
      " -0.6852\n",
      "  3.2498\n",
      " -4.1427\n",
      " -3.3173\n",
      "  3.6161\n",
      " -0.8116\n",
      "  3.7273\n",
      " -0.3436\n",
      "  1.5949\n",
      "  1.0786\n",
      " -1.3924\n",
      " -2.4583\n",
      " -1.0136\n",
      " -3.3521\n",
      "  0.3114\n",
      " -3.1935\n",
      "  0.3356\n",
      "  0.5941\n",
      "  0.4468\n",
      " -1.0248\n",
      " -0.8083\n",
      " -1.2509\n",
      "  3.4376\n",
      "  2.3273\n",
      " -3.8803\n",
      "  0.6055\n",
      "  1.5862\n",
      " -1.7670\n",
      "  2.0138\n",
      " -0.7460\n",
      "  4.2171\n",
      "  0.1279\n",
      " -1.8185\n",
      " -3.3868\n",
      " -2.7183\n",
      " -3.5898\n",
      " -0.2918\n",
      "  1.6128\n",
      " -0.0685\n",
      "  2.0741\n",
      "  1.5503\n",
      "  2.2358\n",
      "  2.0697\n",
      " -0.5944\n",
      "  3.4989\n",
      " -0.0487\n",
      "  1.2270\n",
      "  3.9948\n",
      " -0.2121\n",
      " -4.3970\n",
      "  1.3681\n",
      " -0.4310\n",
      "  0.1670\n",
      " -1.5542\n",
      " -2.6998\n",
      "  1.0402\n",
      "  3.9415\n",
      " -3.4891\n",
      " -3.0414\n",
      "  2.7634\n",
      " -3.6372\n",
      " -3.0353\n",
      " -1.7108\n",
      " -0.0285\n",
      "  2.4134\n",
      " -2.1092\n",
      "  2.7889\n",
      "  1.8340\n",
      " -1.1954\n",
      " -1.8481\n",
      "  4.3321\n",
      "  3.5181\n",
      " -0.9372\n",
      "  2.1928\n",
      "  1.3867\n",
      " -1.6658\n",
      "  0.1162\n",
      "  3.6021\n",
      " -0.6860\n",
      "  2.1299\n",
      " -0.9127\n",
      " -2.6017\n",
      " -0.5133\n",
      "  1.3951\n",
      "  0.4217\n",
      " -2.6145\n",
      " -3.0281\n",
      " -3.9712\n",
      "  0.2024\n",
      "  1.2562\n",
      "  1.3740\n",
      " -0.6655\n",
      "  3.5015\n",
      " -1.8318\n",
      " -2.7532\n",
      "  0.1007\n",
      " -2.5475\n",
      " -4.3542\n",
      " -3.7080\n",
      "  4.3527\n",
      " -0.1843\n",
      "  0.8477\n",
      "  3.4363\n",
      " -3.5779\n",
      "  1.6429\n",
      "  0.2105\n",
      "  0.6327\n",
      " -0.6077\n",
      "  2.6690\n",
      "  1.3845\n",
      "  3.1515\n",
      "  1.5085\n",
      "  2.8017\n",
      "  0.7612\n",
      " -0.4718\n",
      " -2.6401\n",
      "  1.1491\n",
      " -3.7656\n",
      " -1.0646\n",
      "  4.0988\n",
      " -0.4067\n",
      " -3.1727\n",
      " -0.6299\n",
      " -2.6221\n",
      "  0.6621\n",
      " -1.9495\n",
      "  1.1276\n",
      "  0.3299\n",
      " -4.3927\n",
      " -1.7279\n",
      " -3.2320\n",
      " -0.3689\n",
      " -1.3400\n",
      " -3.1106\n",
      "  1.6420\n",
      " -0.6412\n",
      " -3.2506\n",
      " -0.5529\n",
      " -4.2068\n",
      " -2.9801\n",
      " -3.6900\n",
      "  2.9835\n",
      " -1.3297\n",
      " -4.3196\n",
      "  0.3928\n",
      "  2.0001\n",
      " -4.0870\n",
      " -0.7723\n",
      "  3.9457\n",
      "  3.3405\n",
      "  0.5259\n",
      " -2.7313\n",
      "  3.2911\n",
      " -0.7798\n",
      " -0.2213\n",
      " -2.4616\n",
      " -1.4061\n",
      "  1.1950\n",
      "  3.6814\n",
      "  2.1463\n",
      "  3.4494\n",
      " -1.8797\n",
      "  2.3454\n",
      " -1.2440\n",
      " -3.0986\n",
      " -3.6194\n",
      "  3.4963\n",
      "  1.6321\n",
      " -1.0761\n",
      "  1.7979\n",
      " -2.0044\n",
      " -3.4816\n",
      " -1.1688\n",
      " -2.3934\n",
      " -1.1037\n",
      "  2.0315\n",
      "  1.5500\n",
      "  4.0404\n",
      "  2.6426\n",
      "  2.0006\n",
      "  1.6992\n",
      " -2.2441\n",
      " -1.9823\n",
      "  0.0807\n",
      " -4.0875\n",
      "  1.8262\n",
      "  1.5387\n",
      " -0.2152\n",
      " -3.7825\n",
      " -4.0274\n",
      " -1.3496\n",
      " -4.1340\n",
      "  3.6164\n",
      "  3.8486\n",
      "  1.5477\n",
      "  2.8058\n",
      " -1.8890\n",
      "  0.6360\n",
      "  1.4447\n",
      "  0.4472\n",
      "  1.9712\n",
      " -3.2675\n",
      "  2.7919\n",
      " -3.1596\n",
      " -2.1309\n",
      "  1.0093\n",
      "  1.1765\n",
      " -4.2009\n",
      " -1.4212\n",
      " -2.7983\n",
      " -1.9334\n",
      "  2.2710\n",
      "  3.9747\n",
      "  3.9632\n",
      "  4.1886\n",
      "  0.7876\n",
      "  3.4405\n",
      "  1.1454\n",
      "  2.6073\n",
      "  3.7427\n",
      "  0.7020\n",
      " -0.9427\n",
      "  0.4079\n",
      "  3.1415\n",
      " -2.5787\n",
      "  1.7799\n",
      " -3.5821\n",
      "  1.7250\n",
      " -1.1084\n",
      "  0.9953\n",
      "  0.4455\n",
      " -3.5826\n",
      "  3.7184\n",
      " -1.4554\n",
      " -0.7543\n",
      " -2.6679\n",
      "  3.0963\n",
      "  1.9651\n",
      "  0.7179\n",
      "  3.7594\n",
      "  0.6246\n",
      " -2.2340\n",
      " -3.6078\n",
      " -3.6393\n",
      "  0.8314\n",
      " -3.2724\n",
      "  0.8988\n",
      " -3.0943\n",
      "  2.3369\n",
      "  3.8981\n",
      "  2.8071\n",
      "  0.9260\n",
      " -3.2732\n",
      " -1.5264\n",
      " -0.9686\n",
      "  0.6709\n",
      " -1.2764\n",
      " -0.3091\n",
      "  0.9643\n",
      " -1.0982\n",
      "  1.7217\n",
      " -3.5527\n",
      " -3.3221\n",
      "  0.6466\n",
      "  4.0280\n",
      " -0.5591\n",
      "  3.3320\n",
      "  3.7868\n",
      "  3.9003\n",
      " -2.0539\n",
      " -0.3131\n",
      " -1.3714\n",
      "  3.1315\n",
      " -0.1239\n",
      "  4.2767\n",
      "  1.3160\n",
      "  1.5296\n",
      "  4.3121\n",
      " -1.0579\n",
      "  0.4799\n",
      "  2.9628\n",
      "  1.7644\n",
      " -2.7040\n",
      "  4.2942\n",
      " -2.0662\n",
      "  2.9993\n",
      " -2.1233\n",
      "[torch.FloatTensor of size 512]\n",
      "\n",
      "Parameter containing:\n",
      "-2.7395e-03  1.4957e-03  9.5662e-03  ...  -1.0487e-03 -2.2681e-03 -1.2706e-02\n",
      " 1.9554e-02  1.9838e-03 -2.1092e-02  ...  -1.0569e-02  1.3472e-02 -2.8039e-03\n",
      " 2.1031e-02 -8.4048e-03  1.6992e-02  ...  -8.4012e-03  1.4617e-02  1.6544e-02\n",
      "                ...                   ⋱                   ...                \n",
      "-1.9588e-03 -1.8590e-02  1.5828e-02  ...   1.2306e-02  6.6338e-03 -2.0435e-02\n",
      "-6.6176e-03 -5.8444e-03 -1.4072e-02  ...   6.8547e-03  1.3188e-02 -2.1532e-02\n",
      " 2.1978e-02 -1.3298e-02 -1.8015e-02  ...   1.6747e-02  1.2068e-02  3.9181e-03\n",
      "[torch.FloatTensor of size 512x2048]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "  0.6733\n",
      " -0.8535\n",
      "  0.8763\n",
      "  1.9525\n",
      "  1.8796\n",
      "  1.6763\n",
      "  0.8457\n",
      " -1.7854\n",
      "  0.5978\n",
      " -1.9651\n",
      " -0.7465\n",
      "  0.3364\n",
      "  0.8593\n",
      "  1.1676\n",
      "  1.1923\n",
      "  1.0717\n",
      " -2.1607\n",
      " -0.9631\n",
      " -0.9454\n",
      " -0.5701\n",
      "  2.0626\n",
      " -1.6637\n",
      "  0.6747\n",
      "  1.8174\n",
      " -1.5498\n",
      "  0.2222\n",
      " -1.0641\n",
      " -0.4454\n",
      "  2.1651\n",
      " -1.8383\n",
      "  1.7551\n",
      "  1.4394\n",
      "  1.9647\n",
      "  0.8900\n",
      "  1.5473\n",
      "  2.1981\n",
      "  1.1088\n",
      " -1.8390\n",
      " -0.4040\n",
      "  0.8369\n",
      "  1.2349\n",
      "  0.6612\n",
      " -2.1406\n",
      " -0.3861\n",
      "  1.9835\n",
      "  1.2218\n",
      "  0.7777\n",
      " -1.1369\n",
      "  1.3751\n",
      " -1.8517\n",
      "  2.0141\n",
      " -0.9495\n",
      "  1.5903\n",
      "  1.5378\n",
      " -0.8892\n",
      "  0.1762\n",
      "  2.0807\n",
      "  1.3301\n",
      " -1.1581\n",
      "  0.5713\n",
      "  0.4267\n",
      " -0.4888\n",
      "  0.7620\n",
      "  0.8195\n",
      " -0.8285\n",
      " -2.0181\n",
      "  1.5157\n",
      "  0.2394\n",
      "  0.3348\n",
      " -0.7088\n",
      " -0.7431\n",
      "  1.9023\n",
      "  0.8650\n",
      " -1.7674\n",
      "  1.0649\n",
      " -1.9602\n",
      " -1.4402\n",
      "  0.8748\n",
      "  1.6954\n",
      " -1.3011\n",
      "  1.1703\n",
      " -0.2875\n",
      " -0.5562\n",
      "  0.2725\n",
      " -0.1275\n",
      " -1.3591\n",
      "  1.9408\n",
      " -0.5620\n",
      "  0.5099\n",
      " -1.6268\n",
      " -1.2216\n",
      " -1.1213\n",
      " -0.0951\n",
      " -1.8472\n",
      " -1.2229\n",
      " -1.5695\n",
      "  0.9525\n",
      "  1.7030\n",
      "  2.0315\n",
      "  0.5114\n",
      "  1.5902\n",
      " -0.6150\n",
      " -0.1030\n",
      "  2.0085\n",
      " -0.1788\n",
      " -1.2156\n",
      "  1.1625\n",
      "  0.8473\n",
      "  1.3407\n",
      "  2.1176\n",
      "  0.7452\n",
      "  0.8514\n",
      "  1.2115\n",
      "  1.9589\n",
      " -1.3930\n",
      " -1.0065\n",
      "  2.0686\n",
      " -0.5648\n",
      "  0.2661\n",
      " -1.8110\n",
      "  1.6187\n",
      "  1.6127\n",
      " -1.1825\n",
      "  0.7061\n",
      " -1.6136\n",
      " -0.4951\n",
      "  1.2909\n",
      "  1.7907\n",
      "  0.6636\n",
      " -0.3315\n",
      "  0.9534\n",
      "  0.3691\n",
      "  1.3923\n",
      " -0.9598\n",
      "  1.3583\n",
      "  1.4100\n",
      " -0.7596\n",
      " -0.7155\n",
      " -1.9282\n",
      " -1.7558\n",
      " -2.1000\n",
      " -1.8041\n",
      " -0.8775\n",
      "  1.7419\n",
      "  1.9378\n",
      "  0.4897\n",
      "  1.3504\n",
      "  1.3675\n",
      "  1.9168\n",
      "  2.1992\n",
      "  0.5938\n",
      "  0.8794\n",
      "  0.6503\n",
      "  2.0059\n",
      " -0.1430\n",
      "  0.9930\n",
      " -1.5297\n",
      "  0.5241\n",
      "  0.9858\n",
      " -1.4274\n",
      "  0.1308\n",
      "  1.9941\n",
      " -1.7253\n",
      " -1.0431\n",
      " -2.1029\n",
      "  2.1150\n",
      "  0.2441\n",
      "  0.9118\n",
      " -0.4181\n",
      " -1.4746\n",
      "  1.2747\n",
      " -1.3829\n",
      "  1.9942\n",
      "  1.6166\n",
      " -2.1626\n",
      "  0.0648\n",
      " -1.8756\n",
      "  0.9526\n",
      "  0.5243\n",
      "  2.1849\n",
      " -0.4872\n",
      " -0.8739\n",
      " -0.9362\n",
      "  1.4512\n",
      " -1.2007\n",
      " -0.4717\n",
      "  1.7216\n",
      "  0.1917\n",
      " -1.3578\n",
      "  1.7600\n",
      " -0.0389\n",
      "  0.1587\n",
      " -2.0850\n",
      "  0.7756\n",
      "  0.9392\n",
      "  0.3958\n",
      " -0.8111\n",
      " -1.3616\n",
      "  0.5435\n",
      " -1.4543\n",
      "  0.9480\n",
      " -0.6794\n",
      " -1.0017\n",
      " -2.0531\n",
      "  0.7917\n",
      "  0.7851\n",
      " -1.2663\n",
      "  2.1562\n",
      " -2.0800\n",
      "  2.1839\n",
      " -0.1896\n",
      " -0.0918\n",
      " -0.5036\n",
      " -2.1250\n",
      "  0.6972\n",
      "  1.1497\n",
      " -1.8472\n",
      " -0.8638\n",
      " -0.6481\n",
      " -0.2689\n",
      "  0.5101\n",
      " -1.3653\n",
      " -0.4545\n",
      "  1.8302\n",
      "  0.5959\n",
      " -0.5150\n",
      "  0.6957\n",
      "  1.3981\n",
      " -0.3137\n",
      " -1.3888\n",
      " -1.2958\n",
      "  0.9495\n",
      "  0.7391\n",
      " -0.7588\n",
      " -0.7342\n",
      "  0.2167\n",
      "  0.8311\n",
      "  2.1381\n",
      "  1.0502\n",
      " -1.7223\n",
      " -1.0370\n",
      "  0.8266\n",
      "  0.8670\n",
      "  1.8658\n",
      "  0.6930\n",
      " -0.0114\n",
      "  2.0082\n",
      "  0.4429\n",
      "  1.8458\n",
      "  0.9883\n",
      " -1.2075\n",
      "  1.2311\n",
      "  0.4362\n",
      "  1.4942\n",
      " -0.2442\n",
      " -1.9293\n",
      "  1.1872\n",
      " -0.2890\n",
      " -0.8865\n",
      "  1.1612\n",
      " -0.4862\n",
      " -0.4496\n",
      "  0.3416\n",
      "  1.7938\n",
      " -0.3741\n",
      "  1.3887\n",
      " -1.2282\n",
      "  2.0450\n",
      " -1.3618\n",
      "  0.1475\n",
      "  1.6551\n",
      " -0.0546\n",
      "  1.4056\n",
      "  1.8680\n",
      " -1.7065\n",
      "  2.0591\n",
      " -0.8873\n",
      " -0.0431\n",
      " -0.6242\n",
      " -0.1552\n",
      "  1.9914\n",
      " -1.4572\n",
      " -0.5456\n",
      " -1.2228\n",
      "  1.0945\n",
      "  1.9529\n",
      " -1.8221\n",
      "  1.7972\n",
      " -1.2531\n",
      "  1.0982\n",
      "  0.4891\n",
      "  0.2496\n",
      " -1.4098\n",
      "  0.8617\n",
      "  0.2618\n",
      "  1.9967\n",
      "  1.4734\n",
      "  0.2443\n",
      " -2.0272\n",
      "  0.5654\n",
      "  1.4151\n",
      "  0.8149\n",
      " -1.6730\n",
      " -0.2398\n",
      "  0.9115\n",
      " -1.5517\n",
      " -1.3742\n",
      " -0.1399\n",
      " -0.2617\n",
      "  0.9994\n",
      "  2.0499\n",
      "  0.9575\n",
      "  0.7851\n",
      " -0.5269\n",
      " -0.9475\n",
      " -1.3194\n",
      "  2.1152\n",
      " -1.5091\n",
      " -1.4209\n",
      "  1.7421\n",
      "  1.5488\n",
      "  0.1368\n",
      " -1.2242\n",
      "  1.2995\n",
      " -0.1817\n",
      " -1.1783\n",
      "  1.3970\n",
      " -0.6508\n",
      " -0.8267\n",
      " -1.8980\n",
      "  1.1517\n",
      " -1.9092\n",
      " -0.6490\n",
      " -0.5647\n",
      " -0.6426\n",
      " -1.6502\n",
      "  1.1406\n",
      " -1.4686\n",
      " -0.2784\n",
      " -1.3882\n",
      " -1.3335\n",
      " -1.3187\n",
      " -0.6480\n",
      " -0.7002\n",
      "  1.9031\n",
      "  1.9112\n",
      " -1.6945\n",
      " -1.5056\n",
      "  2.0676\n",
      " -0.6843\n",
      "  1.3112\n",
      " -1.1159\n",
      "  1.9537\n",
      "  1.6550\n",
      "  0.4109\n",
      "  1.0696\n",
      " -2.0828\n",
      " -0.8589\n",
      "  1.1944\n",
      "  0.2383\n",
      "  1.3811\n",
      " -2.1770\n",
      " -0.7223\n",
      " -0.9937\n",
      " -0.6526\n",
      " -1.1042\n",
      " -0.0385\n",
      "  2.1918\n",
      " -1.3843\n",
      " -1.8681\n",
      "  0.7686\n",
      "  1.1644\n",
      " -0.6196\n",
      " -1.9074\n",
      " -0.1658\n",
      "  0.2649\n",
      "  1.9441\n",
      "  1.3339\n",
      " -1.9660\n",
      "  1.5752\n",
      "  1.9912\n",
      "  0.4576\n",
      " -0.2686\n",
      "  2.1365\n",
      "  0.2120\n",
      " -1.3861\n",
      "  1.9288\n",
      " -1.1303\n",
      "  0.7411\n",
      " -0.2439\n",
      " -1.5917\n",
      " -0.2942\n",
      " -0.6828\n",
      "  0.6248\n",
      " -0.7281\n",
      "  1.2227\n",
      "  0.8372\n",
      " -1.9540\n",
      " -1.2749\n",
      "  1.0208\n",
      "  0.0225\n",
      " -1.9685\n",
      "  0.3751\n",
      " -0.9600\n",
      " -1.5638\n",
      "  1.6228\n",
      "  0.8400\n",
      " -1.0480\n",
      " -2.1302\n",
      "  2.0757\n",
      " -0.1161\n",
      "  0.4945\n",
      "  0.1836\n",
      "  0.2636\n",
      "  0.2249\n",
      "  1.6924\n",
      " -1.6734\n",
      "  1.7259\n",
      "  1.9937\n",
      "  1.6577\n",
      "  1.1436\n",
      " -0.0289\n",
      "  1.9095\n",
      " -0.4904\n",
      " -1.9268\n",
      "  1.4527\n",
      "  1.8777\n",
      " -0.7490\n",
      "  0.0548\n",
      " -1.9164\n",
      "  1.9769\n",
      "  0.1364\n",
      "  0.0015\n",
      " -0.9733\n",
      "  1.8343\n",
      "  1.3560\n",
      "  1.3528\n",
      " -0.1491\n",
      "  0.8080\n",
      " -1.4225\n",
      " -1.1881\n",
      " -1.2855\n",
      " -0.8934\n",
      "  1.2039\n",
      " -0.6126\n",
      "  0.7628\n",
      "  1.6373\n",
      "  1.0154\n",
      "  0.5394\n",
      "  1.0766\n",
      " -1.1814\n",
      " -0.5072\n",
      " -0.2224\n",
      " -1.4760\n",
      "  1.9848\n",
      "  1.4566\n",
      " -0.1967\n",
      " -1.9938\n",
      " -1.3132\n",
      " -1.9700\n",
      "  0.3934\n",
      " -0.6963\n",
      " -0.2471\n",
      " -0.1440\n",
      " -0.4474\n",
      " -2.1072\n",
      " -1.4392\n",
      "  0.1534\n",
      "  0.7842\n",
      "  1.0766\n",
      " -0.3946\n",
      "  1.1585\n",
      " -0.5123\n",
      "  1.5812\n",
      "  1.1002\n",
      " -0.1261\n",
      " -2.0540\n",
      "  0.7713\n",
      " -1.6661\n",
      " -1.7196\n",
      " -0.1048\n",
      " -1.7929\n",
      " -2.0166\n",
      " -0.0441\n",
      "  0.5476\n",
      " -0.7284\n",
      " -0.6295\n",
      " -0.0651\n",
      " -0.0029\n",
      " -1.4371\n",
      " -0.6083\n",
      "  1.8588\n",
      " -0.2766\n",
      " -0.3317\n",
      " -1.0579\n",
      " -0.1665\n",
      "  0.6185\n",
      "  1.1217\n",
      " -0.5750\n",
      "  0.7125\n",
      "  1.8236\n",
      " -1.6681\n",
      " -0.1147\n",
      " -0.1046\n",
      "  1.0530\n",
      " -1.9847\n",
      " -0.1004\n",
      "  0.5116\n",
      " -1.7622\n",
      " -0.3854\n",
      "  2.1516\n",
      "  0.8913\n",
      "[torch.FloatTensor of size 512]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      " 2.5304 -2.1918  4.1124  ...   1.4010 -0.5355 -3.0261\n",
      " 1.9190 -4.1502 -1.8366  ...   2.9622 -3.2505 -3.0992\n",
      "-2.1980  1.4833 -4.0634  ...  -3.4940 -0.6419 -1.6156\n",
      "          ...             ⋱             ...          \n",
      "-2.6139 -2.7212 -0.1357  ...   3.7608  2.2316  4.0295\n",
      " 2.7182 -0.8481 -4.1347  ...   1.0849 -0.1424 -2.3649\n",
      "-1.8034  2.9270  0.3850  ...   2.8217  1.5932  0.7425\n",
      "[torch.FloatTensor of size 10x512]\n",
      "\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "  2.0606\n",
      " -0.9453\n",
      " -0.0354\n",
      "  3.9887\n",
      " -4.1578\n",
      " -3.3259\n",
      " -0.3585\n",
      "  3.8628\n",
      " -2.3654\n",
      " -1.5633\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "Parameter containing:\n",
      " 0.1902\n",
      " 0.9539\n",
      " 0.8941\n",
      " 0.8391\n",
      " 0.6946\n",
      " 0.8899\n",
      " 0.2029\n",
      " 0.9433\n",
      " 0.3661\n",
      " 0.8999\n",
      " 0.1489\n",
      " 0.8179\n",
      " 0.6110\n",
      " 0.9613\n",
      " 0.1329\n",
      " 0.8973\n",
      " 0.0048\n",
      " 0.1332\n",
      " 0.0618\n",
      " 0.7675\n",
      " 0.4040\n",
      " 0.9813\n",
      " 0.0530\n",
      " 0.7216\n",
      " 0.5743\n",
      " 0.1122\n",
      " 0.9687\n",
      " 0.1523\n",
      " 0.8668\n",
      " 0.0673\n",
      " 0.4125\n",
      " 0.3668\n",
      " 0.0448\n",
      " 0.8570\n",
      " 0.5438\n",
      " 0.2803\n",
      " 0.5073\n",
      " 0.9643\n",
      " 0.2825\n",
      " 0.4096\n",
      " 0.2016\n",
      " 0.9008\n",
      " 0.2010\n",
      " 0.9246\n",
      " 0.6106\n",
      " 0.3289\n",
      " 0.4053\n",
      " 0.5335\n",
      " 0.2193\n",
      " 0.3684\n",
      " 0.5353\n",
      " 0.9468\n",
      " 0.8681\n",
      " 0.8291\n",
      " 0.7767\n",
      " 0.4672\n",
      " 0.8479\n",
      " 0.7100\n",
      " 0.1316\n",
      " 0.9564\n",
      " 0.7678\n",
      " 0.3617\n",
      " 0.4213\n",
      " 0.5908\n",
      "[torch.FloatTensor of size 64]\n",
      "\n",
      "Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 64]\n",
      "\n",
      "Parameter containing:\n",
      " 0.7910\n",
      " 0.1645\n",
      " 0.0228\n",
      " 0.5377\n",
      " 0.4536\n",
      " 0.6351\n",
      " 0.9988\n",
      " 0.8135\n",
      " 0.3404\n",
      " 0.1624\n",
      " 0.8622\n",
      " 0.6493\n",
      " 0.6373\n",
      " 0.2658\n",
      " 0.1415\n",
      " 0.4680\n",
      " 0.7505\n",
      " 0.7136\n",
      " 0.1677\n",
      " 0.5053\n",
      " 0.5944\n",
      " 0.0079\n",
      " 0.8824\n",
      " 0.7240\n",
      " 0.6376\n",
      " 0.4314\n",
      " 0.3689\n",
      " 0.1047\n",
      " 0.9675\n",
      " 0.2584\n",
      " 0.8706\n",
      " 0.2994\n",
      " 0.7426\n",
      " 0.3707\n",
      " 0.0458\n",
      " 0.4239\n",
      " 0.0828\n",
      " 0.5343\n",
      " 0.5145\n",
      " 0.7802\n",
      " 0.4318\n",
      " 0.6229\n",
      " 0.5955\n",
      " 0.3177\n",
      " 0.3081\n",
      " 0.8507\n",
      " 0.1158\n",
      " 0.6476\n",
      " 0.1916\n",
      " 0.3855\n",
      " 0.3059\n",
      " 0.4277\n",
      " 0.1607\n",
      " 0.1728\n",
      " 0.1958\n",
      " 0.4455\n",
      " 0.6270\n",
      " 0.0413\n",
      " 0.4553\n",
      " 0.5097\n",
      " 0.2370\n",
      " 0.8460\n",
      " 0.9125\n",
      " 0.2345\n",
      " 0.0722\n",
      " 0.2215\n",
      " 0.5775\n",
      " 0.2530\n",
      " 0.1705\n",
      " 0.6442\n",
      " 0.8387\n",
      " 0.7280\n",
      " 0.2598\n",
      " 0.8941\n",
      " 0.8723\n",
      " 0.2747\n",
      " 0.3218\n",
      " 0.6202\n",
      " 0.8680\n",
      " 0.7063\n",
      " 0.2759\n",
      " 0.8154\n",
      " 0.9612\n",
      " 0.0698\n",
      " 0.5763\n",
      " 0.6105\n",
      " 0.0503\n",
      " 0.0318\n",
      " 0.3059\n",
      " 0.2653\n",
      " 0.9630\n",
      " 0.3874\n",
      " 0.3546\n",
      " 0.3600\n",
      " 0.3777\n",
      " 0.1190\n",
      " 0.4128\n",
      " 0.4241\n",
      " 0.7820\n",
      " 0.9941\n",
      " 0.1760\n",
      " 0.9788\n",
      " 0.2313\n",
      " 0.2775\n",
      " 0.1402\n",
      " 0.4351\n",
      " 0.0935\n",
      " 0.4233\n",
      " 0.5574\n",
      " 0.7358\n",
      " 0.8151\n",
      " 0.0132\n",
      " 0.8297\n",
      " 0.2036\n",
      " 0.4920\n",
      " 0.9277\n",
      " 0.7745\n",
      " 0.3691\n",
      " 0.2107\n",
      " 0.9617\n",
      " 0.9546\n",
      " 0.1905\n",
      " 0.1758\n",
      " 0.3926\n",
      " 0.3495\n",
      " 0.8017\n",
      " 0.0933\n",
      " 0.7559\n",
      "[torch.FloatTensor of size 128]\n",
      "\n",
      "Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 128]\n",
      "\n",
      "Parameter containing:\n",
      " 0.6220\n",
      " 0.4282\n",
      " 0.7815\n",
      " 0.4063\n",
      " 0.2094\n",
      " 0.8159\n",
      " 0.4181\n",
      " 0.2624\n",
      " 0.8685\n",
      " 0.4645\n",
      " 0.5883\n",
      " 0.4392\n",
      " 0.7176\n",
      " 0.7314\n",
      " 0.8936\n",
      " 0.5999\n",
      " 0.2393\n",
      " 0.5440\n",
      " 0.3825\n",
      " 0.3423\n",
      " 0.9805\n",
      " 0.7935\n",
      " 0.1388\n",
      " 0.7167\n",
      " 0.4840\n",
      " 0.6816\n",
      " 0.2164\n",
      " 0.4456\n",
      " 0.6604\n",
      " 0.6222\n",
      " 0.5215\n",
      " 0.6966\n",
      " 0.7680\n",
      " 0.8458\n",
      " 0.4225\n",
      " 0.9661\n",
      " 0.9319\n",
      " 0.1612\n",
      " 0.6826\n",
      " 0.1156\n",
      " 0.6985\n",
      " 0.7592\n",
      " 0.9819\n",
      " 0.6673\n",
      " 0.2120\n",
      " 0.9543\n",
      " 0.2936\n",
      " 0.0321\n",
      " 0.6510\n",
      " 0.9404\n",
      " 0.5862\n",
      " 0.3646\n",
      " 0.2218\n",
      " 0.0382\n",
      " 0.8894\n",
      " 0.8652\n",
      " 0.8157\n",
      " 0.4422\n",
      " 0.7847\n",
      " 0.9295\n",
      " 0.2763\n",
      " 0.1377\n",
      " 0.1868\n",
      " 0.0967\n",
      " 0.9006\n",
      " 0.4222\n",
      " 0.6261\n",
      " 0.5637\n",
      " 0.2434\n",
      " 0.4638\n",
      " 0.8864\n",
      " 0.6676\n",
      " 0.9832\n",
      " 0.8590\n",
      " 0.6207\n",
      " 0.9978\n",
      " 0.0340\n",
      " 0.2360\n",
      " 0.5436\n",
      " 0.1074\n",
      " 0.9612\n",
      " 0.1128\n",
      " 0.5794\n",
      " 0.9847\n",
      " 0.1172\n",
      " 0.0344\n",
      " 0.7253\n",
      " 0.9507\n",
      " 0.8381\n",
      " 0.6898\n",
      " 0.5166\n",
      " 0.2636\n",
      " 0.9922\n",
      " 0.3943\n",
      " 0.3780\n",
      " 0.5013\n",
      " 0.1615\n",
      " 0.5746\n",
      " 0.5960\n",
      " 0.8845\n",
      " 0.7559\n",
      " 0.4768\n",
      " 0.2164\n",
      " 0.6092\n",
      " 0.9232\n",
      " 0.0878\n",
      " 0.1022\n",
      " 0.2371\n",
      " 0.5411\n",
      " 0.8862\n",
      " 0.9784\n",
      " 0.2142\n",
      " 0.6936\n",
      " 0.0657\n",
      " 0.2626\n",
      " 0.8425\n",
      " 0.3940\n",
      " 0.7378\n",
      " 0.8656\n",
      " 0.8072\n",
      " 0.6946\n",
      " 0.7228\n",
      " 0.6918\n",
      " 0.6740\n",
      " 0.9155\n",
      " 0.6696\n",
      " 0.3405\n",
      " 0.0360\n",
      " 0.7569\n",
      " 0.6505\n",
      " 0.8059\n",
      " 0.4840\n",
      " 0.9168\n",
      " 0.5402\n",
      " 0.9130\n",
      " 0.2873\n",
      " 0.7824\n",
      " 0.4993\n",
      " 0.4436\n",
      " 0.3121\n",
      " 0.8503\n",
      " 0.9657\n",
      " 0.0865\n",
      " 0.9996\n",
      " 0.1898\n",
      " 0.5675\n",
      " 0.0743\n",
      " 0.1811\n",
      " 0.5029\n",
      " 0.5479\n",
      " 0.6189\n",
      " 0.9680\n",
      " 0.9826\n",
      " 0.9988\n",
      " 0.4795\n",
      " 0.8740\n",
      " 0.1190\n",
      " 0.3726\n",
      " 0.9516\n",
      " 0.1205\n",
      " 0.9760\n",
      " 0.5496\n",
      " 0.3016\n",
      " 0.9401\n",
      " 0.3940\n",
      " 0.6168\n",
      " 0.4351\n",
      " 0.5780\n",
      " 0.9930\n",
      " 0.9007\n",
      " 0.6853\n",
      " 0.3277\n",
      " 0.1896\n",
      " 0.3717\n",
      " 0.9634\n",
      " 0.3071\n",
      " 0.6881\n",
      " 0.7526\n",
      " 0.0342\n",
      " 0.4798\n",
      " 0.4963\n",
      " 0.4364\n",
      " 0.6403\n",
      " 0.5318\n",
      " 0.2805\n",
      " 0.4202\n",
      " 0.4826\n",
      " 0.1384\n",
      " 0.9733\n",
      " 0.3676\n",
      " 0.2470\n",
      " 0.3560\n",
      " 0.6646\n",
      " 0.4817\n",
      " 0.3371\n",
      " 0.7588\n",
      " 0.8656\n",
      " 0.5490\n",
      " 0.4920\n",
      " 0.4128\n",
      " 0.8387\n",
      " 0.6380\n",
      " 0.3218\n",
      " 0.5872\n",
      " 0.4182\n",
      " 0.0082\n",
      " 0.8149\n",
      " 0.4005\n",
      " 0.9806\n",
      " 0.4633\n",
      " 0.4488\n",
      " 0.7967\n",
      " 0.2472\n",
      " 0.2345\n",
      " 0.1135\n",
      " 0.0470\n",
      " 0.8503\n",
      " 0.4565\n",
      " 0.2232\n",
      " 0.7662\n",
      " 0.9721\n",
      " 0.1376\n",
      " 0.0217\n",
      " 0.2683\n",
      " 0.2750\n",
      " 0.9460\n",
      " 0.7968\n",
      " 0.8038\n",
      " 0.8844\n",
      " 0.9703\n",
      " 0.1434\n",
      " 0.9124\n",
      " 0.9182\n",
      " 0.0600\n",
      " 0.4211\n",
      " 0.0157\n",
      " 0.1353\n",
      " 0.3545\n",
      " 0.8714\n",
      " 0.8883\n",
      " 0.5682\n",
      " 0.7423\n",
      " 0.7101\n",
      " 0.2331\n",
      " 0.6190\n",
      " 0.7369\n",
      " 0.3914\n",
      " 0.2417\n",
      " 0.0934\n",
      " 0.0269\n",
      " 0.0209\n",
      " 0.9328\n",
      " 0.5058\n",
      " 0.7076\n",
      " 0.0547\n",
      " 0.9800\n",
      "[torch.FloatTensor of size 256]\n",
      "\n",
      "Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 256]\n",
      "\n",
      "Parameter containing:\n",
      " 0.8302\n",
      " 0.6395\n",
      " 0.9867\n",
      " 0.2730\n",
      " 0.1147\n",
      " 0.1697\n",
      " 0.7022\n",
      " 0.4496\n",
      " 0.4923\n",
      " 0.5062\n",
      " 0.5164\n",
      " 0.0725\n",
      " 0.5468\n",
      " 0.7120\n",
      " 0.7171\n",
      " 0.8842\n",
      " 0.3643\n",
      " 0.9652\n",
      " 0.3732\n",
      " 0.8669\n",
      " 0.2900\n",
      " 0.2815\n",
      " 0.0998\n",
      " 0.3365\n",
      " 0.0978\n",
      " 0.2334\n",
      " 0.8040\n",
      " 0.8201\n",
      " 0.2602\n",
      " 0.6388\n",
      " 0.2376\n",
      " 0.7484\n",
      " 0.0833\n",
      " 0.0579\n",
      " 0.1970\n",
      " 0.8595\n",
      " 0.6943\n",
      " 0.2064\n",
      " 0.3500\n",
      " 0.8265\n",
      " 0.3434\n",
      " 0.6779\n",
      " 0.6965\n",
      " 0.2786\n",
      " 0.6286\n",
      " 0.1062\n",
      " 0.9827\n",
      " 0.8291\n",
      " 0.5048\n",
      " 0.2953\n",
      " 0.8727\n",
      " 0.3775\n",
      " 0.6319\n",
      " 0.9413\n",
      " 0.8981\n",
      " 0.7481\n",
      " 0.6331\n",
      " 0.2781\n",
      " 0.7166\n",
      " 0.1863\n",
      " 0.4092\n",
      " 0.4474\n",
      " 0.1576\n",
      " 0.5651\n",
      " 0.3167\n",
      " 0.7869\n",
      " 0.7989\n",
      " 0.4879\n",
      " 0.0590\n",
      " 0.8852\n",
      " 0.6300\n",
      " 0.1349\n",
      " 0.3370\n",
      " 0.2513\n",
      " 0.6374\n",
      " 0.2092\n",
      " 0.8940\n",
      " 0.0537\n",
      " 0.1474\n",
      " 0.8721\n",
      " 0.8243\n",
      " 0.1376\n",
      " 0.4291\n",
      " 0.4749\n",
      " 0.3717\n",
      " 0.8381\n",
      " 0.0687\n",
      " 0.6126\n",
      " 0.3252\n",
      " 0.1210\n",
      " 0.5746\n",
      " 0.9776\n",
      " 0.3074\n",
      " 0.5326\n",
      " 0.6861\n",
      " 0.1772\n",
      " 0.0100\n",
      " 0.5102\n",
      " 0.5675\n",
      " 0.7368\n",
      " 0.6822\n",
      " 0.3423\n",
      " 0.4944\n",
      " 0.0883\n",
      " 0.5709\n",
      " 0.7356\n",
      " 0.4015\n",
      " 0.7912\n",
      " 0.2522\n",
      " 0.6718\n",
      " 0.0174\n",
      " 0.5772\n",
      " 0.1183\n",
      " 0.2458\n",
      " 0.2256\n",
      " 0.9325\n",
      " 0.0368\n",
      " 0.5574\n",
      " 0.3998\n",
      " 0.2012\n",
      " 0.2412\n",
      " 0.8172\n",
      " 0.4227\n",
      " 0.7175\n",
      " 0.4913\n",
      " 0.9941\n",
      " 0.9992\n",
      " 0.4249\n",
      " 0.1646\n",
      " 0.1194\n",
      " 0.9185\n",
      " 0.4912\n",
      " 0.6285\n",
      " 0.4686\n",
      " 0.9046\n",
      " 0.2795\n",
      " 0.5300\n",
      " 0.3918\n",
      " 0.5643\n",
      " 0.8500\n",
      " 0.9994\n",
      " 0.8167\n",
      " 0.3257\n",
      " 0.3243\n",
      " 0.8467\n",
      " 0.7508\n",
      " 0.4642\n",
      " 0.4483\n",
      " 0.1777\n",
      " 0.3891\n",
      " 0.7209\n",
      " 0.1921\n",
      " 0.9338\n",
      " 0.1910\n",
      " 0.9603\n",
      " 0.1780\n",
      " 0.5669\n",
      " 0.7801\n",
      " 0.4890\n",
      " 0.3817\n",
      " 0.1354\n",
      " 0.5262\n",
      " 0.3312\n",
      " 0.0835\n",
      " 0.2470\n",
      " 0.6020\n",
      " 0.2827\n",
      " 0.1123\n",
      " 0.2316\n",
      " 0.2279\n",
      " 0.9159\n",
      " 0.2944\n",
      " 0.3121\n",
      " 0.4998\n",
      " 0.6786\n",
      " 0.0112\n",
      " 0.5972\n",
      " 0.3343\n",
      " 0.5221\n",
      " 0.3975\n",
      " 0.3939\n",
      " 0.2410\n",
      " 0.3212\n",
      " 0.3144\n",
      " 0.9429\n",
      " 0.7347\n",
      " 0.4191\n",
      " 0.3958\n",
      " 0.6987\n",
      " 0.8013\n",
      " 0.6213\n",
      " 0.4551\n",
      " 0.7102\n",
      " 0.2963\n",
      " 0.5871\n",
      " 0.0016\n",
      " 0.1526\n",
      " 0.2431\n",
      " 0.8347\n",
      " 0.1760\n",
      " 0.4203\n",
      " 0.8528\n",
      " 0.2218\n",
      " 0.0070\n",
      " 0.7809\n",
      " 0.8058\n",
      " 0.6305\n",
      " 0.9913\n",
      " 0.6155\n",
      " 0.1245\n",
      " 0.8725\n",
      " 0.4640\n",
      " 0.1857\n",
      " 0.4978\n",
      " 0.8804\n",
      " 0.7413\n",
      " 0.6540\n",
      " 0.2843\n",
      " 0.7086\n",
      " 0.3747\n",
      " 0.2699\n",
      " 0.2259\n",
      " 0.0911\n",
      " 0.3747\n",
      " 0.6770\n",
      " 0.4400\n",
      " 0.8106\n",
      " 0.8725\n",
      " 0.5885\n",
      " 0.3733\n",
      " 0.7134\n",
      " 0.5898\n",
      " 0.8140\n",
      " 0.6925\n",
      " 0.4878\n",
      " 0.5968\n",
      " 0.6055\n",
      " 0.9365\n",
      " 0.1445\n",
      " 0.4953\n",
      " 0.4901\n",
      " 0.1177\n",
      " 0.1257\n",
      " 0.0001\n",
      " 0.5388\n",
      " 0.1851\n",
      " 0.3997\n",
      " 0.8762\n",
      " 0.4749\n",
      " 0.8682\n",
      " 0.2099\n",
      " 0.1881\n",
      " 0.5725\n",
      " 0.4514\n",
      " 0.9293\n",
      " 0.3495\n",
      " 0.9762\n",
      " 0.3849\n",
      " 0.8326\n",
      " 0.7345\n",
      " 0.3110\n",
      " 0.1170\n",
      " 0.3206\n",
      " 0.6351\n",
      " 0.6522\n",
      " 0.1655\n",
      " 0.1941\n",
      " 0.7835\n",
      " 0.0297\n",
      " 0.0227\n",
      " 0.2443\n",
      " 0.3454\n",
      " 0.4945\n",
      " 0.9713\n",
      " 0.2610\n",
      " 0.2121\n",
      " 0.7689\n",
      " 0.5563\n",
      " 0.9455\n",
      " 0.0353\n",
      " 0.8095\n",
      " 0.6463\n",
      " 0.0103\n",
      " 0.9332\n",
      " 0.9627\n",
      " 0.6229\n",
      " 0.7322\n",
      " 0.3057\n",
      " 0.0232\n",
      " 0.3135\n",
      " 0.1468\n",
      " 0.0637\n",
      " 0.2215\n",
      " 0.9365\n",
      " 0.4118\n",
      " 0.0616\n",
      " 0.9235\n",
      " 0.2571\n",
      " 0.7301\n",
      " 0.1554\n",
      " 0.2728\n",
      " 0.0149\n",
      " 0.0462\n",
      " 0.0359\n",
      " 0.8849\n",
      " 0.3967\n",
      " 0.2054\n",
      " 0.1361\n",
      " 0.8013\n",
      " 0.1208\n",
      " 0.1455\n",
      " 0.8289\n",
      " 0.9480\n",
      " 0.4596\n",
      " 0.0026\n",
      " 0.7107\n",
      " 0.2343\n",
      " 0.1608\n",
      " 0.4991\n",
      " 0.0428\n",
      " 0.3057\n",
      " 0.6749\n",
      " 0.6946\n",
      " 0.6431\n",
      " 0.3655\n",
      " 0.4239\n",
      " 0.1187\n",
      " 0.8644\n",
      " 0.5575\n",
      " 0.1020\n",
      " 0.8858\n",
      " 0.3724\n",
      " 0.0724\n",
      " 0.6667\n",
      " 0.0520\n",
      " 0.0701\n",
      " 0.6803\n",
      " 0.3493\n",
      " 0.0787\n",
      " 0.5549\n",
      " 0.4986\n",
      " 0.7711\n",
      " 0.2570\n",
      " 0.5405\n",
      " 0.9523\n",
      " 0.2816\n",
      " 0.5281\n",
      " 0.3934\n",
      " 0.2762\n",
      " 0.2178\n",
      " 0.0587\n",
      " 0.0771\n",
      " 0.6820\n",
      " 0.4750\n",
      " 0.8680\n",
      " 0.9069\n",
      " 0.3756\n",
      " 0.3605\n",
      " 0.5383\n",
      " 0.3709\n",
      " 0.0528\n",
      " 0.7560\n",
      " 0.4247\n",
      " 0.0605\n",
      " 0.3579\n",
      " 0.3764\n",
      " 0.4397\n",
      " 0.0291\n",
      " 0.7879\n",
      " 0.3276\n",
      " 0.0514\n",
      " 0.7495\n",
      " 0.3106\n",
      " 0.6001\n",
      " 0.4797\n",
      " 0.5194\n",
      " 0.7794\n",
      " 0.4122\n",
      " 0.9661\n",
      " 0.8730\n",
      " 0.8206\n",
      " 0.8374\n",
      " 0.3865\n",
      " 0.8267\n",
      " 0.4980\n",
      " 0.0496\n",
      " 0.7697\n",
      " 0.1979\n",
      " 0.3405\n",
      " 0.3408\n",
      " 0.4252\n",
      " 0.3374\n",
      " 0.6383\n",
      " 0.4627\n",
      " 0.0962\n",
      " 0.9263\n",
      " 0.9247\n",
      " 0.1284\n",
      " 0.6798\n",
      " 0.5656\n",
      " 0.7209\n",
      " 0.9444\n",
      " 0.1926\n",
      " 0.9633\n",
      " 0.9579\n",
      " 0.4923\n",
      " 0.6593\n",
      " 0.1802\n",
      " 0.4022\n",
      " 0.1115\n",
      " 0.8579\n",
      " 0.9020\n",
      " 0.1086\n",
      " 0.3268\n",
      " 0.3681\n",
      " 0.0631\n",
      " 0.3373\n",
      " 0.7236\n",
      " 0.5985\n",
      " 0.1513\n",
      " 0.3914\n",
      " 0.3127\n",
      " 0.0471\n",
      " 0.8968\n",
      " 0.5946\n",
      " 0.1391\n",
      " 0.2020\n",
      " 0.3665\n",
      " 0.8456\n",
      " 0.7254\n",
      " 0.8509\n",
      " 0.2012\n",
      " 0.0876\n",
      " 0.2554\n",
      " 0.6841\n",
      " 0.3336\n",
      " 0.9921\n",
      " 0.2841\n",
      " 0.9536\n",
      " 0.0587\n",
      " 0.6084\n",
      " 0.6763\n",
      " 0.5793\n",
      " 0.5390\n",
      " 0.4261\n",
      " 0.4598\n",
      " 0.9678\n",
      " 0.7050\n",
      " 0.7755\n",
      " 0.1868\n",
      " 0.5717\n",
      " 0.3428\n",
      " 0.6485\n",
      " 0.7271\n",
      " 0.0745\n",
      " 0.6680\n",
      " 0.2069\n",
      " 0.5415\n",
      " 0.9073\n",
      " 0.8527\n",
      " 0.7458\n",
      " 0.1973\n",
      " 0.8429\n",
      " 0.8667\n",
      " 0.6275\n",
      " 0.8109\n",
      " 0.4107\n",
      " 0.9837\n",
      " 0.1719\n",
      " 0.1462\n",
      " 0.0154\n",
      " 0.4280\n",
      " 0.4581\n",
      " 0.5239\n",
      " 0.3620\n",
      " 0.8247\n",
      " 0.1384\n",
      " 0.4301\n",
      " 0.5043\n",
      " 0.8384\n",
      " 0.5841\n",
      " 0.2294\n",
      " 0.6868\n",
      " 0.8900\n",
      " 0.3440\n",
      " 0.4236\n",
      " 0.8582\n",
      " 0.2531\n",
      " 0.4932\n",
      " 0.6126\n",
      " 0.4178\n",
      " 0.9278\n",
      " 0.4757\n",
      " 0.2343\n",
      " 0.7007\n",
      " 0.3440\n",
      " 0.7296\n",
      " 0.0301\n",
      " 0.1431\n",
      " 0.2996\n",
      " 0.0946\n",
      " 0.3094\n",
      " 0.7256\n",
      " 0.1090\n",
      " 0.3192\n",
      " 0.5797\n",
      " 0.9610\n",
      " 0.6843\n",
      " 0.5005\n",
      " 0.6532\n",
      " 0.2843\n",
      " 0.3593\n",
      "[torch.FloatTensor of size 512]\n",
      "\n",
      "Parameter containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# 3. Define a Loss function and optimizer\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.adam(model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-32:\n",
      "Process Process-31:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 342, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rafal/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rafal/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 55, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/datasets/cifar.py\", line 122, in __getitem__\n",
      "    img = self.transform(img)\n",
      "  File \"/home/rafal/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms/transforms.py\", line 42, in __call__\n",
      "    img = t(img)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n",
      "    return F.to_tensor(pic)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torchvision/transforms/functional.py\", line 76, in to_tensor\n",
      "    return img.float().div(255)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f5b70da00f0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rafal/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rafal/.local/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 345, in get\n",
      "    return ForkingPickler.loads(res)\n",
      "  File \"/home/rafal/.local/lib/python3.5/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.5/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-6628a2bff759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    loss_train_epoch = 0 \n",
    "    correct_train_epoch = 0\n",
    "    loss_test_epoch = 0\n",
    "    correct_test_epoch = 0\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    " \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_epoch += loss.data[0]\n",
    "        correct_train_epoch += (outputs.max(1)[1] == labels).sum().data[0]\n",
    "\n",
    "    avg_loss_train = loss_train_epoch / len(trainloader.dataset)\n",
    "    avg_acc_train = correct_train_epoch / len(trainloader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss_test_epoch += loss.data[0]\n",
    "        correct_test_epoch += (outputs.max(1)[1] == labels).sum().data[0]\n",
    "\n",
    "    avg_loss_test = loss_test_epoch / len(testloader.dataset)\n",
    "    avg_acc_test = correct_test_epoch / len(testloader.dataset)\n",
    "\n",
    "\n",
    "    print(\"Epoch {} \\n\".format(epoch+1),\n",
    "    \"avg_training_loss: {} \\n\".format(avg_loss_train),\n",
    "    \"avg_training_acc: {} \\n\".format(avg_acc_train),\n",
    "    \"avg_test_loss: {} \\n\".format(avg_loss_test),\n",
    "    \"avg_test_acc: {} \\n\".format(avg_acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
